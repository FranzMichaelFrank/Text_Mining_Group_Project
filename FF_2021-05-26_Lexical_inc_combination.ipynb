{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aboriginal-contamination",
   "metadata": {},
   "source": [
    "# TM Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-thomas",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "final-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coated-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "\n",
    "path_corpus = \"/Users/franz/Desktop/TM Project/corpus/\"\n",
    "\n",
    "ru_en = pd.read_csv(path_corpus + \"ru-en/scores.csv\")\n",
    "de_en = pd.read_csv(path_corpus + \"de-en/scores.csv\")\n",
    "cs_en = pd.read_csv(path_corpus + \"cs-en/scores.csv\")\n",
    "zh_en = pd.read_csv(path_corpus + \"zh-en/scores.csv\")\n",
    "en_zh = pd.read_csv(path_corpus + \"en-zh/scores.csv\")\n",
    "en_fi = pd.read_csv(path_corpus + \"en-fi/scores.csv\")\n",
    "\n",
    "ru_en_ = ru_en.copy()\n",
    "de_en_ = de_en.copy()\n",
    "cs_en_ = cs_en.copy()\n",
    "zh_en_ = zh_en.copy()\n",
    "en_zh_ = en_zh.copy()\n",
    "en_fi_ = en_fi.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opponent-updating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr Zeitlupentempo maßen sie, als sie vor Spit...</td>\n",
       "      <td>Her timeless pace measures them when they equi...</td>\n",
       "      <td>Their slow speed was measured by researchers o...</td>\n",
       "      <td>-0.345024</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Er sagte, dass die Bereiche ruhige Treffpunkte...</td>\n",
       "      <td>He said the areas offer quiet meeting points b...</td>\n",
       "      <td>He said the spaces provided calm meeting point...</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>97.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Für die Geschäftsleute an der B 27 ist es nur ...</td>\n",
       "      <td>For businessmen at the B 27, it's only a small...</td>\n",
       "      <td>This is only a small consolation for businesse...</td>\n",
       "      <td>0.700503</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diese Fähigkeit sei möglicherweise angeboren o...</td>\n",
       "      <td>This ability may be born or developed with gen...</td>\n",
       "      <td>This ability may be innate, or may develop as ...</td>\n",
       "      <td>-1.256572</td>\n",
       "      <td>51.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weil sie Wassertemperaturen um die sechs Grad ...</td>\n",
       "      <td>Because they prefer water temperatures around ...</td>\n",
       "      <td>They generally only come to the surface in win...</td>\n",
       "      <td>0.293909</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Ihr Zeitlupentempo maßen sie, als sie vor Spit...   \n",
       "1  Er sagte, dass die Bereiche ruhige Treffpunkte...   \n",
       "2  Für die Geschäftsleute an der B 27 ist es nur ...   \n",
       "3  Diese Fähigkeit sei möglicherweise angeboren o...   \n",
       "4  Weil sie Wassertemperaturen um die sechs Grad ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Her timeless pace measures them when they equi...   \n",
       "1  He said the areas offer quiet meeting points b...   \n",
       "2  For businessmen at the B 27, it's only a small...   \n",
       "3  This ability may be born or developed with gen...   \n",
       "4  Because they prefer water temperatures around ...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Their slow speed was measured by researchers o... -0.345024       76.0   \n",
       "1  He said the spaces provided calm meeting point...  0.903800       97.5   \n",
       "2  This is only a small consolation for businesse...  0.700503       94.0   \n",
       "3  This ability may be innate, or may develop as ... -1.256572       51.5   \n",
       "4  They generally only come to the surface in win...  0.293909       87.0   \n",
       "\n",
       "   annotators  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           2  \n",
       "4           2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-fitness",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "christian-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = [\"Russian into English\", \"German into English\", \"Czech into English\", \"Chinese into English\", \"English into Chinese\", \"English into Finish\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smoking-stroke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>avg z-score</th>\n",
       "      <th>avg avg-score</th>\n",
       "      <th>avg annotators</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Russian into English</th>\n",
       "      <td>17980.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>74.50</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German into English</th>\n",
       "      <td>21704.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.85</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Czech into English</th>\n",
       "      <td>11585.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>69.24</td>\n",
       "      <td>1.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinese into English</th>\n",
       "      <td>26419.0</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>66.06</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Chinese</th>\n",
       "      <td>10221.0</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>65.98</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Finish</th>\n",
       "      <td>6748.0</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>45.12</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         rows  avg z-score  avg avg-score  avg annotators\n",
       "description                                                              \n",
       "Russian into English  17980.0         0.01          74.50            1.30\n",
       "German into English   21704.0         0.00          71.85            1.50\n",
       "Czech into English    11585.0        -0.03          69.24            1.89\n",
       "Chinese into English  26419.0        -0.05          66.06            1.42\n",
       "English into Chinese  10221.0        -0.06          65.98            1.58\n",
       "English into Finish    6748.0        -0.14          45.12            1.23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "zscores = []\n",
    "avgscores = []\n",
    "annots = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    rows.append(element.shape[0])\n",
    "    zscores.append(np.round(element[\"z-score\"].mean(),2))\n",
    "    avgscores.append(np.round(element[\"avg-score\"].mean(), 2))\n",
    "    annots.append(np.round(element[\"annotators\"].mean(),2))\n",
    "    i += 1                   \n",
    "    \n",
    "exploration_df = pd.DataFrame([rows, zscores, avgscores, annots]).T.rename(columns={0:\"rows\", 1:\"avg z-score\", 2:\"avg avg-score\", 3:\"avg annotators\"})\n",
    "exploration_df[\"description\"] = descriptions\n",
    "exploration_df = exploration_df.set_index(\"description\")\n",
    "exploration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "agricultural-selection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>avg z-score</th>\n",
       "      <th>avg avg-score</th>\n",
       "      <th>avg annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rows</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.597505</td>\n",
       "      <td>0.579839</td>\n",
       "      <td>-0.105454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg z-score</th>\n",
       "      <td>0.597505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975645</td>\n",
       "      <td>0.310459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg avg-score</th>\n",
       "      <td>0.579839</td>\n",
       "      <td>0.975645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.417110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg annotators</th>\n",
       "      <td>-0.105454</td>\n",
       "      <td>0.310459</td>\n",
       "      <td>0.417110</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    rows  avg z-score  avg avg-score  avg annotators\n",
       "rows            1.000000     0.597505       0.579839       -0.105454\n",
       "avg z-score     0.597505     1.000000       0.975645        0.310459\n",
       "avg avg-score   0.579839     0.975645       1.000000        0.417110\n",
       "avg annotators -0.105454     0.310459       0.417110        1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploration_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-president",
   "metadata": {},
   "source": [
    "As there are only 6 different types of translations, these correlations might be not very meaningful!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-intellectual",
   "metadata": {},
   "source": [
    "# Lexical metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-contract",
   "metadata": {},
   "source": [
    "## BLEU Score - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "compact-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# a more \"pythonic\" way to compute BLUE_star \n",
    "\n",
    "def BLEU_star_compact(refs, candidate):\n",
    "    refs = [refs.split()]\n",
    "    candidate = candidate.split()\n",
    "\n",
    "    return sum([min(count, max([ref[word] for ref in [Counter(ref) for ref in refs]])) for word, count in Counter(candidate).items()])/len(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-rolling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCorrelation between z-score and BLEU score\n",
      "\n",
      "\u001b[1m Russian into English: \u001b[0mPearson: 0.3337 | Kendall: 0.2284\n",
      "\u001b[1m German into English: \u001b[0mPearson: 0.2987 | Kendall: 0.2104\n",
      "\u001b[1m Czech into English: \u001b[0mPearson: 0.4252 | Kendall: 0.2886\n",
      "\u001b[1m Chinese into English: \u001b[0mPearson: 0.3132 | Kendall: 0.2118\n",
      "\u001b[1m English into Chinese: \u001b[0mPearson: 0.0256 | Kendall: 0.0046\n",
      "\u001b[1m English into Finish: \u001b[0mPearson: 0.5084 | Kendall: 0.3383\n",
      "\n",
      "\u001b[1mOverall:\u001b[0m Average Pearson: 0.3174 | Average Kendall: 0.2137\n"
     ]
    }
   ],
   "source": [
    "overall_results = {}\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "\n",
    "co = 0\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    bleu_scores = []\n",
    "\n",
    "    #calculating the bleu scores for the translations in comparison to their respective reference\n",
    "    for i in range(element.shape[0]): #element.shape[0]\n",
    "        reference = element.loc[i,\"reference\"]\n",
    "        translation = element.loc[i,\"translation\"]\n",
    "        bleu_scores.append(BLEU_star_compact(reference, translation))\n",
    "\n",
    "    #add the bleu scores to the dataframe\n",
    "    development_df = element.copy() #element.shape[0]\n",
    "    development_df[\"BLEU\"] = bleu_scores\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "    \n",
    "    if co == 0:\n",
    "        ru_en_[\"BLEU\"] = bleu_scores\n",
    "    elif co == 1:\n",
    "        de_en_[\"BLEU\"] = bleu_scores\n",
    "    elif co == 2:\n",
    "        cs_en_[\"BLEU\"] = bleu_scores\n",
    "    elif co == 3:\n",
    "        zh_en_[\"BLEU\"] = bleu_scores\n",
    "    elif co == 4:\n",
    "        en_zh_[\"BLEU\"] = bleu_scores\n",
    "    elif co == 5:\n",
    "        en_fi_[\"BLEU\"] = bleu_scores\n",
    "    co += 1\n",
    "        \n",
    "\n",
    "\n",
    "print(\"\\033[1mCorrelation between z-score and BLEU score\\n\")\n",
    "i = 0\n",
    "for element in correlations_p:\n",
    "    print(\"\\033[1m\", descriptions[i] + \":\",  \"\\033[0mPearson:\", np.round(element,4), \"| Kendall:\", np.round(correlations_k[i],4))\n",
    "    i += 1\n",
    "\n",
    "print(\"\\n\\033[1mOverall:\\033[0m Average Pearson:\", np.round(sum(correlations_p)/len(correlations_p),4),\n",
    "         \"| Average Kendall:\", np.round(sum(correlations_k)/len(correlations_k),4))\n",
    "\n",
    "overall_results[\"BLEU Star Pearson\"] = correlations_p\n",
    "overall_results[\"BLEU Star Kendall\"] = correlations_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-explanation",
   "metadata": {},
   "source": [
    "## BLEU Score - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-desperate",
   "metadata": {},
   "source": [
    "### 1st Try (sentence_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "million-yeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCorrelation between z-score and BLEU score\n",
      "\n",
      "\u001b[1m Russian into English: \u001b[0mPearson: 0.2541 | Kendall: 0.1899\n",
      "\u001b[1m German into English: \u001b[0mPearson: 0.2419 | Kendall: 0.1769\n",
      "\u001b[1m Czech into English: \u001b[0mPearson: 0.2924 | Kendall: 0.2256\n",
      "\u001b[1m Chinese into English: \u001b[0mPearson: 0.2458 | Kendall: 0.1791\n",
      "\u001b[1m English into Chinese: \u001b[0mPearson: 0.0141 | Kendall: 0.0045\n",
      "\u001b[1m English into Finish: \u001b[0mPearson: 0.2623 | Kendall: 0.2896\n",
      "\n",
      "\u001b[1mOverall:\u001b[0m Average Pearson: 0.2184 | Average Kendall: 0.1776\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "\n",
    "co = 0\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    bleu_scores = []\n",
    "\n",
    "    #calculating the bleu scores for the translations in comparison to their respective reference\n",
    "    for i in range(element.shape[0]): #element.shape[0]\n",
    "        reference = [element.loc[i,\"reference\"].split()]\n",
    "        translation = element.loc[i,\"translation\"].split()\n",
    "        bleu_scores.append(sentence_bleu(reference, translation,weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n",
    "    #add the bleu scores to the dataframe\n",
    "    development_df = element.copy() #element.shape[0]\n",
    "    development_df[\"BLEU\"] = bleu_scores\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "    \n",
    "    if co == 0:\n",
    "        ru_en_[\"BLEU_s\"] = bleu_scores\n",
    "    elif co == 1:\n",
    "        de_en_[\"BLEU_s\"] = bleu_scores\n",
    "    elif co == 2:\n",
    "        cs_en_[\"BLEU_s\"] = bleu_scores\n",
    "    elif co == 3:\n",
    "        zh_en_[\"BLEU_s\"] = bleu_scores\n",
    "    elif co == 4:\n",
    "        en_zh_[\"BLEU_s\"] = bleu_scores\n",
    "    elif co == 5:\n",
    "        en_fi_[\"BLEU_s\"] = bleu_scores\n",
    "\n",
    "    co += 1\n",
    "    \n",
    "print(\"\\033[1mCorrelation between z-score and BLEU score\\n\")\n",
    "i = 0\n",
    "for element in correlations_p:\n",
    "    print(\"\\033[1m\", descriptions[i] + \":\",  \"\\033[0mPearson:\", np.round(element,4), \"| Kendall:\", np.round(correlations_k[i],4))\n",
    "    i += 1\n",
    "\n",
    "print(\"\\n\\033[1mOverall:\\033[0m Average Pearson:\", np.round(sum(correlations_p)/len(correlations_p),4),\n",
    "         \"| Average Kendall:\", np.round(sum(correlations_k)/len(correlations_k),4))\n",
    "\n",
    "overall_results[\"BLEU Sentence Pearson\"] = correlations_p\n",
    "overall_results[\"BLEU Sentence Kendall\"] = correlations_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-amber",
   "metadata": {},
   "source": [
    "### 2nd Try (corpus_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adolescent-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCorrelation between z-score and BLEU score\n",
      "\n",
      "\u001b[1m Russian into English: \u001b[0mPearson 0.0539 | Kendall: 0.0628\n",
      "\u001b[1m German into English: \u001b[0mPearson 0.0065 | Kendall: 0.0394\n",
      "\u001b[1m Czech into English: \u001b[0mPearson 0.0923 | Kendall: 0.0982\n",
      "\u001b[1m Chinese into English: \u001b[0mPearson 0.0547 | Kendall: 0.0484\n",
      "\u001b[1m English into Chinese: \u001b[0mPearson 0.4243 | Kendall: 0.2997\n",
      "\u001b[1m English into Finish: \u001b[0mPearson 0.2355 | Kendall: 0.1723\n",
      "\n",
      "\u001b[1mOverall:\u001b[0m Average Pearson: 0.1445 | Average Kendall: 0.1201\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "\n",
    "co = 0\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    bleu_scores = []\n",
    "\n",
    "    #calculating the bleu scores for the translations in comparison to their respective reference\n",
    "    for i in range(element.shape[0]): #element.shape[0]\n",
    "        reference = [element.loc[i,\"reference\"].split()]\n",
    "        translation = element.loc[i,\"translation\"].split()\n",
    "        while len(reference) < len(translation):\n",
    "            reference.append(\" \")\n",
    "        while len(reference) > len(translation):\n",
    "            translation.append(\" \")\n",
    "        bleu_scores.append(corpus_bleu(reference, translation))\n",
    "\n",
    "    #add the bleu scores to the dataframe\n",
    "    development_df = element.copy() #element.shape[0]\n",
    "    development_df[\"BLEU\"] = bleu_scores\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "    \n",
    "    if co == 0:\n",
    "        ru_en_[\"BLEU_c\"] = bleu_scores\n",
    "    elif co == 1:\n",
    "        de_en_[\"BLEU_c\"] = bleu_scores\n",
    "    elif co == 2:\n",
    "        cs_en_[\"BLEU_c\"] = bleu_scores\n",
    "    elif co == 3:\n",
    "        zh_en_[\"BLEU_c\"] = bleu_scores\n",
    "    elif co == 4:\n",
    "        en_zh_[\"BLEU_c\"] = bleu_scores\n",
    "    elif co == 5:\n",
    "        en_fi_[\"BLEU_c\"] = bleu_scores\n",
    "    co += 1\n",
    "    i += 1\n",
    "\n",
    "\n",
    "print(\"\\033[1mCorrelation between z-score and BLEU score\\n\")\n",
    "i = 0\n",
    "for element in correlations_p:\n",
    "    print(\"\\033[1m\", descriptions[i] + \":\",  \"\\033[0mPearson\", np.round(element,4), \"| Kendall:\", np.round(correlations_k[i],4))\n",
    "    i += 1\n",
    "\n",
    "print(\"\\n\\033[1mOverall:\\033[0m Average Pearson:\", np.round(sum(correlations_p)/len(correlations_p),4),\n",
    "         \"| Average Kendall:\", np.round(sum(correlations_k)/len(correlations_k),4))\n",
    "\n",
    "overall_results[\"BLEU Corpus Pearson\"] = correlations_p\n",
    "overall_results[\"BLEU Corpus Kendall\"] = correlations_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-divide",
   "metadata": {},
   "source": [
    "## ROUGE Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-donor",
   "metadata": {},
   "source": [
    "### ROUGE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "everyday-oxford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPearson Correlation between z-score and ROUGE measures (ROUGE 1) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.344109</td>\n",
       "      <td>0.316624</td>\n",
       "      <td>0.456718</td>\n",
       "      <td>0.331985</td>\n",
       "      <td>0.074533</td>\n",
       "      <td>0.549302</td>\n",
       "      <td>0.345545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.294337</td>\n",
       "      <td>0.294263</td>\n",
       "      <td>0.390546</td>\n",
       "      <td>0.277619</td>\n",
       "      <td>0.075061</td>\n",
       "      <td>0.513220</td>\n",
       "      <td>0.307508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.341309</td>\n",
       "      <td>0.326557</td>\n",
       "      <td>0.450511</td>\n",
       "      <td>0.328195</td>\n",
       "      <td>0.080697</td>\n",
       "      <td>0.544540</td>\n",
       "      <td>0.345302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.344109             0.316624   \n",
       "ROUGE recall                 0.294337             0.294263   \n",
       "ROUGE fmeasure               0.341309             0.326557   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.456718              0.331985   \n",
       "ROUGE recall               0.390546              0.277619   \n",
       "ROUGE fmeasure             0.450511              0.328195   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.074533             0.549302  0.345545  \n",
       "ROUGE recall                 0.075061             0.513220  0.307508  \n",
       "ROUGE fmeasure               0.080697             0.544540  0.345302  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "results_p = pd.DataFrame()\n",
    "results_k = pd.DataFrame()\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "j = 0\n",
    "co = 0\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    fmeasures = []\n",
    "\n",
    "    #calculating the rouge scores for the translations in comparison to their respective reference\n",
    "    for i in range(element.shape[0]): #element.shape[0]\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(element.loc[i,\"reference\"], element.loc[i,\"translation\"])\n",
    "        precisions.append(scores[\"rouge1\"].precision)\n",
    "        recalls.append(scores[\"rouge1\"].recall)\n",
    "        fmeasures.append(scores[\"rouge1\"].fmeasure)\n",
    "\n",
    "    #add the rouge scores to the dataframe\n",
    "    development_df = element.copy() #element.shape[0]\n",
    "    development_df[\"ROUGE precision\"] = precisions\n",
    "    development_df[\"ROUGE recall\"] = recalls\n",
    "    development_df[\"ROUGE fmeasure\"] = fmeasures\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "    col_name = descriptions[j]\n",
    "    j += 1\n",
    "    results_p[col_name] = pd.Series(development_df.corr(method=\"pearson\").iloc[0,3:])\n",
    "    results_k[col_name] = pd.Series(development_df.corr(method=\"kendall\").iloc[0,3:])\n",
    "    \n",
    "    if co == 0:\n",
    "        ru_en_[\"ROUGE1_precision\"] = precisions\n",
    "        ru_en_[\"ROUGE1_recall\"] = recalls\n",
    "        ru_en_[\"ROUGE1_fmeasure\"] = fmeasures\n",
    "    elif co == 1:\n",
    "        de_en_[\"ROUGE1_precision\"] = precisions\n",
    "        de_en_[\"ROUGE1_recall\"] = recalls\n",
    "        de_en_[\"ROUGE1_fmeasure\"] = fmeasures\n",
    "    elif co == 2:\n",
    "        cs_en_[\"ROUGE1_precision\"] = precisions\n",
    "        cs_en_[\"ROUGE1_recall\"] = recalls\n",
    "        cs_en_[\"ROUGE1_fmeasure\"] = fmeasures\n",
    "    elif co == 3:\n",
    "        zh_en_[\"ROUGE1_precision\"] = precisions\n",
    "        zh_en_[\"ROUGE1_recall\"] = recalls\n",
    "        zh_en_[\"ROUGE1_fmeasure\"] = fmeasures\n",
    "    elif co == 4:\n",
    "        en_zh_[\"ROUGE1_precision\"] = precisions\n",
    "        en_zh_[\"ROUGE1_recall\"] = recalls\n",
    "        en_zh_[\"ROUGE1_fmeasure\"] = fmeasures\n",
    "    elif co == 5:\n",
    "        en_fi_[\"ROUGE1_precision\"] = precisions\n",
    "        en_fi_[\"ROUGE1_recall\"] = recalls\n",
    "        en_fi_[\"ROUGE1_fmeasure\"] = fmeasures\n",
    "    co += 1\n",
    "\n",
    "\n",
    "print(\"\\033[1mPearson Correlation between z-score and ROUGE measures (ROUGE 1) \\n\")\n",
    "\n",
    "\n",
    "overall_results[\"ROUGE 1 Precision Pearson\"] = results_p.iloc[0,:6].values.tolist()\n",
    "overall_results[\"ROUGE 1 Recall Pearson\"] = results_p.iloc[1,:6].values.tolist()\n",
    "overall_results[\"ROUGE 1 Fmeasure Pearson\"] = results_p.iloc[2,:6].values.tolist()\n",
    "\n",
    "results_p[\"Average\"] = results_p.T.mean()\n",
    "results_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "shared-death",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mKendall Tau Correlation between z-score and ROUGE measures (ROUGE 1) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.233533</td>\n",
       "      <td>0.219705</td>\n",
       "      <td>0.307255</td>\n",
       "      <td>0.220957</td>\n",
       "      <td>0.050288</td>\n",
       "      <td>0.363198</td>\n",
       "      <td>0.232489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.200764</td>\n",
       "      <td>0.203551</td>\n",
       "      <td>0.260756</td>\n",
       "      <td>0.181468</td>\n",
       "      <td>0.050626</td>\n",
       "      <td>0.332239</td>\n",
       "      <td>0.204901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.233055</td>\n",
       "      <td>0.225082</td>\n",
       "      <td>0.302951</td>\n",
       "      <td>0.216623</td>\n",
       "      <td>0.054556</td>\n",
       "      <td>0.354801</td>\n",
       "      <td>0.231178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.233533             0.219705   \n",
       "ROUGE recall                 0.200764             0.203551   \n",
       "ROUGE fmeasure               0.233055             0.225082   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.307255              0.220957   \n",
       "ROUGE recall               0.260756              0.181468   \n",
       "ROUGE fmeasure             0.302951              0.216623   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.050288             0.363198  0.232489  \n",
       "ROUGE recall                 0.050626             0.332239  0.204901  \n",
       "ROUGE fmeasure               0.054556             0.354801  0.231178  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\033[1mKendall Tau Correlation between z-score and ROUGE measures (ROUGE 1) \\n\")\n",
    "\n",
    "overall_results[\"ROUGE 1 Precision Kendall\"] = results_k.iloc[0,:6].values.tolist()\n",
    "overall_results[\"ROUGE 1 Recall Kendall\"] = results_k.iloc[1,:6].values.tolist()\n",
    "overall_results[\"ROUGE 1 Fmeasure Kendall\"] = results_k.iloc[2,:6].values.tolist()\n",
    "\n",
    "results_k[\"Average\"] = results_k.T.mean()\n",
    "results_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-times",
   "metadata": {},
   "source": [
    "### ROUGE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "figured-punch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPearson Correlation between z-score and ROUGE measures (ROUGE 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.326187</td>\n",
       "      <td>0.301237</td>\n",
       "      <td>0.412951</td>\n",
       "      <td>0.308727</td>\n",
       "      <td>0.088139</td>\n",
       "      <td>0.468350</td>\n",
       "      <td>0.317599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.301894</td>\n",
       "      <td>0.288012</td>\n",
       "      <td>0.380923</td>\n",
       "      <td>0.285887</td>\n",
       "      <td>0.092338</td>\n",
       "      <td>0.444354</td>\n",
       "      <td>0.298901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.320052</td>\n",
       "      <td>0.301592</td>\n",
       "      <td>0.405594</td>\n",
       "      <td>0.304461</td>\n",
       "      <td>0.095062</td>\n",
       "      <td>0.461915</td>\n",
       "      <td>0.314779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.326187             0.301237   \n",
       "ROUGE recall                 0.301894             0.288012   \n",
       "ROUGE fmeasure               0.320052             0.301592   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.412951              0.308727   \n",
       "ROUGE recall               0.380923              0.285887   \n",
       "ROUGE fmeasure             0.405594              0.304461   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.088139             0.468350  0.317599  \n",
       "ROUGE recall                 0.092338             0.444354  0.298901  \n",
       "ROUGE fmeasure               0.095062             0.461915  0.314779  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "results_p = pd.DataFrame()\n",
    "results_k = pd.DataFrame()\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "j = 0\n",
    "co = 0\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    fmeasures = []\n",
    "\n",
    "    #calculating the rouge scores for the translations in comparison to their respective reference\n",
    "    for i in range(element.shape[0]): #element.shape[0]\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(element.loc[i,\"reference\"], element.loc[i,\"translation\"])\n",
    "        precisions.append(scores[\"rouge2\"].precision)\n",
    "        recalls.append(scores[\"rouge2\"].recall)\n",
    "        fmeasures.append(scores[\"rouge2\"].fmeasure)\n",
    "\n",
    "    #add the rouge scores to the dataframe\n",
    "    development_df = element.copy() #element.shape[0]\n",
    "    development_df[\"ROUGE precision\"] = precisions\n",
    "    development_df[\"ROUGE recall\"] = recalls\n",
    "    development_df[\"ROUGE fmeasure\"] = fmeasures\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "    col_name = descriptions[j]\n",
    "    j += 1\n",
    "    results_p[col_name] = pd.Series(development_df.corr(method=\"pearson\").iloc[0,3:])\n",
    "    results_k[col_name] = pd.Series(development_df.corr(method=\"kendall\").iloc[0,3:])\n",
    "    \n",
    "    if co == 0:\n",
    "        ru_en_[\"ROUGE2_precision\"] = precisions\n",
    "        ru_en_[\"ROUGE2_recall\"] = recalls\n",
    "        ru_en_[\"ROUGE2_fmeasure\"] = fmeasures\n",
    "    elif co == 1:\n",
    "        de_en_[\"ROUGE2_precision\"] = precisions\n",
    "        de_en_[\"ROUGE2_recall\"] = recalls\n",
    "        de_en_[\"ROUGE2_fmeasure\"] = fmeasures\n",
    "    elif co == 2:\n",
    "        cs_en_[\"ROUGE2_precision\"] = precisions\n",
    "        cs_en_[\"ROUGE2_recall\"] = recalls\n",
    "        cs_en_[\"ROUGE2_fmeasure\"] = fmeasures\n",
    "    elif co == 3:\n",
    "        zh_en_[\"ROUGE2_precision\"] = precisions\n",
    "        zh_en_[\"ROUGE2_recall\"] = recalls\n",
    "        zh_en_[\"ROUGE2_fmeasure\"] = fmeasures\n",
    "    elif co == 4:\n",
    "        en_zh_[\"ROUGE2_precision\"] = precisions\n",
    "        en_zh_[\"ROUGE2_recall\"] = recalls\n",
    "        en_zh_[\"ROUGE2_fmeasure\"] = fmeasures\n",
    "    elif co == 5:\n",
    "        en_fi_[\"ROUGE2_precision\"] = precisions\n",
    "        en_fi_[\"ROUGE2_recall\"] = recalls\n",
    "        en_fi_[\"ROUGE2_fmeasure\"] = fmeasures\n",
    "    co += 1\n",
    "\n",
    "\n",
    "print(\"\\033[1mPearson Correlation between z-score and ROUGE measures (ROUGE 2) \\n\")\n",
    "\n",
    "overall_results[\"ROUGE 2 Precision Pearson\"] = results_p.iloc[0,:6].values.tolist()\n",
    "overall_results[\"ROUGE 2 Recall Pearson\"] = results_p.iloc[1,:6].values.tolist()\n",
    "overall_results[\"ROUGE 2 Fmeasure Pearson\"] = results_p.iloc[2,:6].values.tolist()\n",
    "\n",
    "results_p[\"Average\"] = results_p.T.mean()\n",
    "results_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "given-syndication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mKendall Tau Correlation between z-score and ROUGE measures (ROUGE 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.229159</td>\n",
       "      <td>0.213632</td>\n",
       "      <td>0.286637</td>\n",
       "      <td>0.208257</td>\n",
       "      <td>0.067758</td>\n",
       "      <td>0.320441</td>\n",
       "      <td>0.220981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.213027</td>\n",
       "      <td>0.202720</td>\n",
       "      <td>0.262969</td>\n",
       "      <td>0.192289</td>\n",
       "      <td>0.068840</td>\n",
       "      <td>0.304527</td>\n",
       "      <td>0.207395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.224302</td>\n",
       "      <td>0.211171</td>\n",
       "      <td>0.278814</td>\n",
       "      <td>0.203703</td>\n",
       "      <td>0.069508</td>\n",
       "      <td>0.314192</td>\n",
       "      <td>0.216948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.229159             0.213632   \n",
       "ROUGE recall                 0.213027             0.202720   \n",
       "ROUGE fmeasure               0.224302             0.211171   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.286637              0.208257   \n",
       "ROUGE recall               0.262969              0.192289   \n",
       "ROUGE fmeasure             0.278814              0.203703   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.067758             0.320441  0.220981  \n",
       "ROUGE recall                 0.068840             0.304527  0.207395  \n",
       "ROUGE fmeasure               0.069508             0.314192  0.216948  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\033[1mKendall Tau Correlation between z-score and ROUGE measures (ROUGE 2) \\n\")\n",
    "\n",
    "overall_results[\"ROUGE 2 Precision Kendall\"] = results_k.iloc[0,:6].values.tolist()\n",
    "overall_results[\"ROUGE 2 Recall Kendall\"] = results_k.iloc[1,:6].values.tolist()\n",
    "overall_results[\"ROUGE 2 Fmeasure Kendall\"] = results_k.iloc[2,:6].values.tolist()\n",
    "\n",
    "results_k[\"Average\"] = results_k.T.mean()\n",
    "results_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-valley",
   "metadata": {},
   "source": [
    "### ROUGE L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "thermal-virgin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPearson Correlation between z-score and ROUGE measures (ROUGE L) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.355554</td>\n",
       "      <td>0.321503</td>\n",
       "      <td>0.470087</td>\n",
       "      <td>0.347083</td>\n",
       "      <td>0.076326</td>\n",
       "      <td>0.540008</td>\n",
       "      <td>0.351760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.300898</td>\n",
       "      <td>0.411121</td>\n",
       "      <td>0.305689</td>\n",
       "      <td>0.077659</td>\n",
       "      <td>0.505371</td>\n",
       "      <td>0.319290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.352986</td>\n",
       "      <td>0.327532</td>\n",
       "      <td>0.461447</td>\n",
       "      <td>0.344989</td>\n",
       "      <td>0.082974</td>\n",
       "      <td>0.535137</td>\n",
       "      <td>0.350844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.355554             0.321503   \n",
       "ROUGE recall                 0.315000             0.300898   \n",
       "ROUGE fmeasure               0.352986             0.327532   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.470087              0.347083   \n",
       "ROUGE recall               0.411121              0.305689   \n",
       "ROUGE fmeasure             0.461447              0.344989   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.076326             0.540008  0.351760  \n",
       "ROUGE recall                 0.077659             0.505371  0.319290  \n",
       "ROUGE fmeasure               0.082974             0.535137  0.350844  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "results_p = pd.DataFrame()\n",
    "results_k = pd.DataFrame()\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "j = 0\n",
    "co = 0\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    fmeasures = []\n",
    "\n",
    "    #calculating the rouge scores for the translations in comparison to their respective reference\n",
    "    for i in range(element.shape[0]): #element.shape[0]\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(element.loc[i,\"reference\"], element.loc[i,\"translation\"])\n",
    "        precisions.append(scores[\"rougeL\"].precision)\n",
    "        recalls.append(scores[\"rougeL\"].recall)\n",
    "        fmeasures.append(scores[\"rougeL\"].fmeasure)\n",
    "\n",
    "    #add the rouge scores to the dataframe\n",
    "    development_df = element.copy() #element.shape[0]\n",
    "    development_df[\"ROUGE precision\"] = precisions\n",
    "    development_df[\"ROUGE recall\"] = recalls\n",
    "    development_df[\"ROUGE fmeasure\"] = fmeasures\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "    col_name = descriptions[j]\n",
    "    j += 1\n",
    "    results_p[col_name] = pd.Series(development_df.corr(method=\"pearson\").iloc[0,3:])\n",
    "    results_k[col_name] = pd.Series(development_df.corr(method=\"kendall\").iloc[0,3:])\n",
    "    \n",
    "    if co == 0:\n",
    "        ru_en_[\"ROUGEL_precision\"] = precisions\n",
    "        ru_en_[\"ROUGEL_recall\"] = recalls\n",
    "        ru_en_[\"ROUGEL_fmeasure\"] = fmeasures\n",
    "    elif co == 1:\n",
    "        de_en_[\"ROUGEL_precision\"] = precisions\n",
    "        de_en_[\"ROUGEL_recall\"] = recalls\n",
    "        de_en_[\"ROUGEL_fmeasure\"] = fmeasures\n",
    "    elif co == 2:\n",
    "        cs_en_[\"ROUGEL_precision\"] = precisions\n",
    "        cs_en_[\"ROUGEL_recall\"] = recalls\n",
    "        cs_en_[\"ROUGEL_fmeasure\"] = fmeasures\n",
    "    elif co == 3:\n",
    "        zh_en_[\"ROUGEL_precision\"] = precisions\n",
    "        zh_en_[\"ROUGEL_recall\"] = recalls\n",
    "        zh_en_[\"ROUGEL_fmeasure\"] = fmeasures\n",
    "    elif co == 4:\n",
    "        en_zh_[\"ROUGEL_precision\"] = precisions\n",
    "        en_zh_[\"ROUGEL_recall\"] = recalls\n",
    "        en_zh_[\"ROUGEL_fmeasure\"] = fmeasures\n",
    "    elif co == 5:\n",
    "        en_fi_[\"ROUGEL_precision\"] = precisions\n",
    "        en_fi_[\"ROUGEL_recall\"] = recalls\n",
    "        en_fi_[\"ROUGEL_fmeasure\"] = fmeasures\n",
    "    co += 1\n",
    "    \n",
    "\n",
    "\n",
    "print(\"\\033[1mPearson Correlation between z-score and ROUGE measures (ROUGE L) \\n\")\n",
    "\n",
    "overall_results[\"ROUGE L Precision Pearson\"] = results_p.iloc[0,:6].values.tolist()\n",
    "overall_results[\"ROUGE L Recall Pearson\"] = results_p.iloc[1,:6].values.tolist()\n",
    "overall_results[\"ROUGE L Fmeasure Pearson\"] = results_p.iloc[2,:6].values.tolist()\n",
    "\n",
    "results_p[\"Average\"] = results_p.T.mean()\n",
    "results_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "increased-millennium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mKendall Tau Correlation between z-score and ROUGE measures (ROUGE L) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.247499</td>\n",
       "      <td>0.228066</td>\n",
       "      <td>0.318498</td>\n",
       "      <td>0.235286</td>\n",
       "      <td>0.050533</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.239264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.221562</td>\n",
       "      <td>0.212349</td>\n",
       "      <td>0.278319</td>\n",
       "      <td>0.207330</td>\n",
       "      <td>0.051499</td>\n",
       "      <td>0.326671</td>\n",
       "      <td>0.216288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.246683</td>\n",
       "      <td>0.229880</td>\n",
       "      <td>0.311631</td>\n",
       "      <td>0.231499</td>\n",
       "      <td>0.054923</td>\n",
       "      <td>0.347729</td>\n",
       "      <td>0.237058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.247499             0.228066   \n",
       "ROUGE recall                 0.221562             0.212349   \n",
       "ROUGE fmeasure               0.246683             0.229880   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.318498              0.235286   \n",
       "ROUGE recall               0.278319              0.207330   \n",
       "ROUGE fmeasure             0.311631              0.231499   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.050533             0.355700  0.239264  \n",
       "ROUGE recall                 0.051499             0.326671  0.216288  \n",
       "ROUGE fmeasure               0.054923             0.347729  0.237058  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\033[1mKendall Tau Correlation between z-score and ROUGE measures (ROUGE L) \\n\")\n",
    "\n",
    "overall_results[\"ROUGE L Precision Kendall\"] = results_k.iloc[0,:6].values.tolist()\n",
    "overall_results[\"ROUGE L Recall Kendall\"] = results_k.iloc[1,:6].values.tolist()\n",
    "overall_results[\"ROUGE L Fmeasure Kendall\"] = results_k.iloc[2,:6].values.tolist()\n",
    "\n",
    "results_k[\"Average\"] = results_k.T.mean()\n",
    "results_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-pension",
   "metadata": {},
   "source": [
    "## RESULTS TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "neither-portland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLEU Star Pearson</th>\n",
       "      <td>0.333658</td>\n",
       "      <td>0.298661</td>\n",
       "      <td>0.425182</td>\n",
       "      <td>0.313196</td>\n",
       "      <td>0.025590</td>\n",
       "      <td>0.508383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU Sentence Pearson</th>\n",
       "      <td>0.254081</td>\n",
       "      <td>0.241926</td>\n",
       "      <td>0.292354</td>\n",
       "      <td>0.245847</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.262296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU Corpus Pearson</th>\n",
       "      <td>0.053877</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.092340</td>\n",
       "      <td>0.054715</td>\n",
       "      <td>0.424316</td>\n",
       "      <td>0.235517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Precision Pearson</th>\n",
       "      <td>0.344109</td>\n",
       "      <td>0.316624</td>\n",
       "      <td>0.456718</td>\n",
       "      <td>0.331985</td>\n",
       "      <td>0.074533</td>\n",
       "      <td>0.549302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Recall Pearson</th>\n",
       "      <td>0.294337</td>\n",
       "      <td>0.294263</td>\n",
       "      <td>0.390546</td>\n",
       "      <td>0.277619</td>\n",
       "      <td>0.075061</td>\n",
       "      <td>0.513220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Fmeasure Pearson</th>\n",
       "      <td>0.341309</td>\n",
       "      <td>0.326557</td>\n",
       "      <td>0.450511</td>\n",
       "      <td>0.328195</td>\n",
       "      <td>0.080697</td>\n",
       "      <td>0.544540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Precision Pearson</th>\n",
       "      <td>0.326187</td>\n",
       "      <td>0.301237</td>\n",
       "      <td>0.412951</td>\n",
       "      <td>0.308727</td>\n",
       "      <td>0.088139</td>\n",
       "      <td>0.468350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Recall Pearson</th>\n",
       "      <td>0.301894</td>\n",
       "      <td>0.288012</td>\n",
       "      <td>0.380923</td>\n",
       "      <td>0.285887</td>\n",
       "      <td>0.092338</td>\n",
       "      <td>0.444354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Fmeasure Pearson</th>\n",
       "      <td>0.320052</td>\n",
       "      <td>0.301592</td>\n",
       "      <td>0.405594</td>\n",
       "      <td>0.304461</td>\n",
       "      <td>0.095062</td>\n",
       "      <td>0.461915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Precision Pearson</th>\n",
       "      <td>0.355554</td>\n",
       "      <td>0.321503</td>\n",
       "      <td>0.470087</td>\n",
       "      <td>0.347083</td>\n",
       "      <td>0.076326</td>\n",
       "      <td>0.540008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Recall Pearson</th>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.300898</td>\n",
       "      <td>0.411121</td>\n",
       "      <td>0.305689</td>\n",
       "      <td>0.077659</td>\n",
       "      <td>0.505371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Fmeasure Pearson</th>\n",
       "      <td>0.352986</td>\n",
       "      <td>0.327532</td>\n",
       "      <td>0.461447</td>\n",
       "      <td>0.344989</td>\n",
       "      <td>0.082974</td>\n",
       "      <td>0.535137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Russian into English  German into English  \\\n",
       "BLEU Star Pearson                      0.333658             0.298661   \n",
       "BLEU Sentence Pearson                  0.254081             0.241926   \n",
       "BLEU Corpus Pearson                    0.053877             0.006482   \n",
       "ROUGE 1 Precision Pearson              0.344109             0.316624   \n",
       "ROUGE 1 Recall Pearson                 0.294337             0.294263   \n",
       "ROUGE 1 Fmeasure Pearson               0.341309             0.326557   \n",
       "ROUGE 2 Precision Pearson              0.326187             0.301237   \n",
       "ROUGE 2 Recall Pearson                 0.301894             0.288012   \n",
       "ROUGE 2 Fmeasure Pearson               0.320052             0.301592   \n",
       "ROUGE L Precision Pearson              0.355554             0.321503   \n",
       "ROUGE L Recall Pearson                 0.315000             0.300898   \n",
       "ROUGE L Fmeasure Pearson               0.352986             0.327532   \n",
       "\n",
       "                           Czech into English  Chinese into English  \\\n",
       "BLEU Star Pearson                    0.425182              0.313196   \n",
       "BLEU Sentence Pearson                0.292354              0.245847   \n",
       "BLEU Corpus Pearson                  0.092340              0.054715   \n",
       "ROUGE 1 Precision Pearson            0.456718              0.331985   \n",
       "ROUGE 1 Recall Pearson               0.390546              0.277619   \n",
       "ROUGE 1 Fmeasure Pearson             0.450511              0.328195   \n",
       "ROUGE 2 Precision Pearson            0.412951              0.308727   \n",
       "ROUGE 2 Recall Pearson               0.380923              0.285887   \n",
       "ROUGE 2 Fmeasure Pearson             0.405594              0.304461   \n",
       "ROUGE L Precision Pearson            0.470087              0.347083   \n",
       "ROUGE L Recall Pearson               0.411121              0.305689   \n",
       "ROUGE L Fmeasure Pearson             0.461447              0.344989   \n",
       "\n",
       "                           English into Chinese  English into Finish  \n",
       "BLEU Star Pearson                      0.025590             0.508383  \n",
       "BLEU Sentence Pearson                  0.014064             0.262296  \n",
       "BLEU Corpus Pearson                    0.424316             0.235517  \n",
       "ROUGE 1 Precision Pearson              0.074533             0.549302  \n",
       "ROUGE 1 Recall Pearson                 0.075061             0.513220  \n",
       "ROUGE 1 Fmeasure Pearson               0.080697             0.544540  \n",
       "ROUGE 2 Precision Pearson              0.088139             0.468350  \n",
       "ROUGE 2 Recall Pearson                 0.092338             0.444354  \n",
       "ROUGE 2 Fmeasure Pearson               0.095062             0.461915  \n",
       "ROUGE L Precision Pearson              0.076326             0.540008  \n",
       "ROUGE L Recall Pearson                 0.077659             0.505371  \n",
       "ROUGE L Fmeasure Pearson               0.082974             0.535137  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsons = []\n",
    "kendalls = []\n",
    "\n",
    "for element in list(overall_results.keys()):\n",
    "    if element.endswith(\"Pearson\"):\n",
    "        pearsons.append(element)\n",
    "    elif element.endswith(\"Kendall\"):\n",
    "        kendalls.append(element)\n",
    "        \n",
    "dict_pearson = { your_key: overall_results[your_key] for your_key in pearsons }\n",
    "dict_kendall = { your_key: overall_results[your_key] for your_key in kendalls }\n",
    "\n",
    "pearson_df = pd.DataFrame(list(dict_pearson.values()), index=list(dict_pearson.keys()), columns=descriptions)\n",
    "pearson_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "intellectual-evans",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric with highest correlation</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Russian into English</th>\n",
       "      <td>ROUGE L Precision Pearson</td>\n",
       "      <td>0.355554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German into English</th>\n",
       "      <td>ROUGE L Fmeasure Pearson</td>\n",
       "      <td>0.327532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Czech into English</th>\n",
       "      <td>ROUGE L Precision Pearson</td>\n",
       "      <td>0.470087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinese into English</th>\n",
       "      <td>ROUGE L Precision Pearson</td>\n",
       "      <td>0.347083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Chinese</th>\n",
       "      <td>BLEU Corpus Pearson</td>\n",
       "      <td>0.424316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Finish</th>\n",
       "      <td>ROUGE 1 Precision Pearson</td>\n",
       "      <td>0.549302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metric with highest correlation     Value\n",
       "Russian into English       ROUGE L Precision Pearson  0.355554\n",
       "German into English         ROUGE L Fmeasure Pearson  0.327532\n",
       "Czech into English         ROUGE L Precision Pearson  0.470087\n",
       "Chinese into English       ROUGE L Precision Pearson  0.347083\n",
       "English into Chinese             BLEU Corpus Pearson  0.424316\n",
       "English into Finish        ROUGE 1 Precision Pearson  0.549302"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_evaluation = pd.DataFrame(pearson_df.idxmax(), columns=[\"Metric with highest correlation\"])\n",
    "pearson_evaluation[\"Value\"] = pearson_df.max()\n",
    "pearson_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tight-cylinder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLEU Star Kendall</th>\n",
       "      <td>0.228402</td>\n",
       "      <td>0.210405</td>\n",
       "      <td>0.288620</td>\n",
       "      <td>0.211820</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>0.338281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU Sentence Kendall</th>\n",
       "      <td>0.189865</td>\n",
       "      <td>0.176866</td>\n",
       "      <td>0.225613</td>\n",
       "      <td>0.179100</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.289645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU Corpus Kendall</th>\n",
       "      <td>0.062795</td>\n",
       "      <td>0.039423</td>\n",
       "      <td>0.098247</td>\n",
       "      <td>0.048396</td>\n",
       "      <td>0.299679</td>\n",
       "      <td>0.172336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Precision Kendall</th>\n",
       "      <td>0.233533</td>\n",
       "      <td>0.219705</td>\n",
       "      <td>0.307255</td>\n",
       "      <td>0.220957</td>\n",
       "      <td>0.050288</td>\n",
       "      <td>0.363198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Recall Kendall</th>\n",
       "      <td>0.200764</td>\n",
       "      <td>0.203551</td>\n",
       "      <td>0.260756</td>\n",
       "      <td>0.181468</td>\n",
       "      <td>0.050626</td>\n",
       "      <td>0.332239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Fmeasure Kendall</th>\n",
       "      <td>0.233055</td>\n",
       "      <td>0.225082</td>\n",
       "      <td>0.302951</td>\n",
       "      <td>0.216623</td>\n",
       "      <td>0.054556</td>\n",
       "      <td>0.354801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Precision Kendall</th>\n",
       "      <td>0.229159</td>\n",
       "      <td>0.213632</td>\n",
       "      <td>0.286637</td>\n",
       "      <td>0.208257</td>\n",
       "      <td>0.067758</td>\n",
       "      <td>0.320441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Recall Kendall</th>\n",
       "      <td>0.213027</td>\n",
       "      <td>0.202720</td>\n",
       "      <td>0.262969</td>\n",
       "      <td>0.192289</td>\n",
       "      <td>0.068840</td>\n",
       "      <td>0.304527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Fmeasure Kendall</th>\n",
       "      <td>0.224302</td>\n",
       "      <td>0.211171</td>\n",
       "      <td>0.278814</td>\n",
       "      <td>0.203703</td>\n",
       "      <td>0.069508</td>\n",
       "      <td>0.314192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Precision Kendall</th>\n",
       "      <td>0.247499</td>\n",
       "      <td>0.228066</td>\n",
       "      <td>0.318498</td>\n",
       "      <td>0.235286</td>\n",
       "      <td>0.050533</td>\n",
       "      <td>0.355700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Recall Kendall</th>\n",
       "      <td>0.221562</td>\n",
       "      <td>0.212349</td>\n",
       "      <td>0.278319</td>\n",
       "      <td>0.207330</td>\n",
       "      <td>0.051499</td>\n",
       "      <td>0.326671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Fmeasure Kendall</th>\n",
       "      <td>0.246683</td>\n",
       "      <td>0.229880</td>\n",
       "      <td>0.311631</td>\n",
       "      <td>0.231499</td>\n",
       "      <td>0.054923</td>\n",
       "      <td>0.347729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Russian into English  German into English  \\\n",
       "BLEU Star Kendall                      0.228402             0.210405   \n",
       "BLEU Sentence Kendall                  0.189865             0.176866   \n",
       "BLEU Corpus Kendall                    0.062795             0.039423   \n",
       "ROUGE 1 Precision Kendall              0.233533             0.219705   \n",
       "ROUGE 1 Recall Kendall                 0.200764             0.203551   \n",
       "ROUGE 1 Fmeasure Kendall               0.233055             0.225082   \n",
       "ROUGE 2 Precision Kendall              0.229159             0.213632   \n",
       "ROUGE 2 Recall Kendall                 0.213027             0.202720   \n",
       "ROUGE 2 Fmeasure Kendall               0.224302             0.211171   \n",
       "ROUGE L Precision Kendall              0.247499             0.228066   \n",
       "ROUGE L Recall Kendall                 0.221562             0.212349   \n",
       "ROUGE L Fmeasure Kendall               0.246683             0.229880   \n",
       "\n",
       "                           Czech into English  Chinese into English  \\\n",
       "BLEU Star Kendall                    0.288620              0.211820   \n",
       "BLEU Sentence Kendall                0.225613              0.179100   \n",
       "BLEU Corpus Kendall                  0.098247              0.048396   \n",
       "ROUGE 1 Precision Kendall            0.307255              0.220957   \n",
       "ROUGE 1 Recall Kendall               0.260756              0.181468   \n",
       "ROUGE 1 Fmeasure Kendall             0.302951              0.216623   \n",
       "ROUGE 2 Precision Kendall            0.286637              0.208257   \n",
       "ROUGE 2 Recall Kendall               0.262969              0.192289   \n",
       "ROUGE 2 Fmeasure Kendall             0.278814              0.203703   \n",
       "ROUGE L Precision Kendall            0.318498              0.235286   \n",
       "ROUGE L Recall Kendall               0.278319              0.207330   \n",
       "ROUGE L Fmeasure Kendall             0.311631              0.231499   \n",
       "\n",
       "                           English into Chinese  English into Finish  \n",
       "BLEU Star Kendall                      0.004606             0.338281  \n",
       "BLEU Sentence Kendall                  0.004496             0.289645  \n",
       "BLEU Corpus Kendall                    0.299679             0.172336  \n",
       "ROUGE 1 Precision Kendall              0.050288             0.363198  \n",
       "ROUGE 1 Recall Kendall                 0.050626             0.332239  \n",
       "ROUGE 1 Fmeasure Kendall               0.054556             0.354801  \n",
       "ROUGE 2 Precision Kendall              0.067758             0.320441  \n",
       "ROUGE 2 Recall Kendall                 0.068840             0.304527  \n",
       "ROUGE 2 Fmeasure Kendall               0.069508             0.314192  \n",
       "ROUGE L Precision Kendall              0.050533             0.355700  \n",
       "ROUGE L Recall Kendall                 0.051499             0.326671  \n",
       "ROUGE L Fmeasure Kendall               0.054923             0.347729  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendall_df = pd.DataFrame(list(dict_kendall.values()), index=list(dict_kendall.keys()), columns=descriptions)\n",
    "kendall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "reverse-herald",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric with highest correlation</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Russian into English</th>\n",
       "      <td>ROUGE L Precision Kendall</td>\n",
       "      <td>0.247499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German into English</th>\n",
       "      <td>ROUGE L Fmeasure Kendall</td>\n",
       "      <td>0.229880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Czech into English</th>\n",
       "      <td>ROUGE L Precision Kendall</td>\n",
       "      <td>0.318498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinese into English</th>\n",
       "      <td>ROUGE L Precision Kendall</td>\n",
       "      <td>0.235286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Chinese</th>\n",
       "      <td>BLEU Corpus Kendall</td>\n",
       "      <td>0.299679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Finish</th>\n",
       "      <td>ROUGE 1 Precision Kendall</td>\n",
       "      <td>0.363198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metric with highest correlation     Value\n",
       "Russian into English       ROUGE L Precision Kendall  0.247499\n",
       "German into English         ROUGE L Fmeasure Kendall  0.229880\n",
       "Czech into English         ROUGE L Precision Kendall  0.318498\n",
       "Chinese into English       ROUGE L Precision Kendall  0.235286\n",
       "English into Chinese             BLEU Corpus Kendall  0.299679\n",
       "English into Finish        ROUGE 1 Precision Kendall  0.363198"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendall_evaluation = pd.DataFrame(kendall_df.idxmax(), columns=[\"Metric with highest correlation\"])\n",
    "kendall_evaluation[\"Value\"] = kendall_df.max()\n",
    "kendall_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-institute",
   "metadata": {},
   "source": [
    "## COMBINATION - Predicting the scores for the testset with the best respective metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "recovered-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "\n",
    "path_corpus_test = \"/Users/franz/Downloads/testset/\"\n",
    "\n",
    "ru_en_test = pd.read_csv(path_corpus_test + \"ru-en/scores.csv\")\n",
    "de_en_test = pd.read_csv(path_corpus_test + \"de-en/scores.csv\")\n",
    "cs_en_test = pd.read_csv(path_corpus_test + \"cs-en/scores.csv\")\n",
    "zh_en_test = pd.read_csv(path_corpus_test + \"zh-en/scores.csv\")\n",
    "en_zh_test = pd.read_csv(path_corpus_test + \"en-zh/scores.csv\")\n",
    "en_fi_test = pd.read_csv(path_corpus_test + \"en-fi/scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-flooring",
   "metadata": {},
   "source": [
    "Throughout all the test set, there is only one field containing a nan, which is ru_en_test.iloc[9191,1]. As the metric score cannot be computed without a reference, this row has to be deleted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bored-hostel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9191</th>\n",
       "      <td>Кот-тяжеловес по кличке Мистер Красавчик нашел...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A heavyweight cat that goes by the nickname of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source reference  \\\n",
       "9191  Кот-тяжеловес по кличке Мистер Красавчик нашел...       NaN   \n",
       "\n",
       "                                            translation  \n",
       "9191  A heavyweight cat that goes by the nickname of...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0 \n",
    "j = 0\n",
    "for element in ru_en_test.isna()[\"reference\"].tolist():\n",
    "    if element == True:\n",
    "        j = i\n",
    "    i +=1\n",
    "    \n",
    "pd.DataFrame(ru_en_test.iloc[j,:]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "documented-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_en_test = ru_en_test.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "impressed-budapest",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "for element in [ru_en_test, de_en_test, cs_en_test, zh_en_test, en_zh_test, en_fi_test]:\n",
    "    \n",
    "    # detect the language pair contained in the dataframe\n",
    "    pair = detect(element.iloc[0,0]) + \"_\" + detect(element.iloc[0,1])\n",
    "    \n",
    "    predicted_scores = []\n",
    "    \n",
    "    if pair in [\"ru_en\", \"cs_en\", \"de_en\", \"zh-cn_en\", \"en_fi\"]:\n",
    "        for i in range(element.shape[0]):\n",
    "            scorer = rouge_scorer.RougeScorer(['rougeL', 'rouge1'], use_stemmer=True)\n",
    "            scores = scorer.score(element.loc[i,\"reference\"], element.loc[i,\"translation\"])\n",
    "            if pair in [\"ru_en\", \"cs_en\"]:\n",
    "                predicted_scores.append(scores[\"rougeL\"].precision)\n",
    "            elif pair == \"de_en\":\n",
    "                predicted_scores.append(scores[\"rougeL\"].fmeasure)\n",
    "            elif pair in [\"zh-cn_en\", \"en_fi\"]:\n",
    "                predicted_scores.append(scores[\"rouge1\"].precision)\n",
    "                \n",
    "    elif pair == \"en_zh-cn\":\n",
    "        for i in range(element.shape[0]):\n",
    "            reference = [element.loc[i,\"reference\"].split()]\n",
    "            translation = element.loc[i,\"translation\"].split()\n",
    "            while len(reference) < len(translation):\n",
    "                reference.append(\" \")\n",
    "            while len(reference) > len(translation):\n",
    "                translation.append(\" \")\n",
    "            predicted_scores.append(corpus_bleu(reference, translation))\n",
    "        \n",
    "            \n",
    "    element[\"predicted_score\"] = predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "crucial-october",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Через полчаса обуглившийся клубень достают и п...</td>\n",
       "      <td>After half an hour, the charred tuber is taken...</td>\n",
       "      <td>After half-an-hour, the charred tuber is retri...</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Здесь никто не думает отменять смертную казнь,...</td>\n",
       "      <td>Here, no one thinks to abolish the death penal...</td>\n",
       "      <td>Here, no one is concerned with abolishing the ...</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собеседники \"Известий\" в ОНФ отмечают, что док...</td>\n",
       "      <td>The interlocutors of\" Izvestiya \"in the onf no...</td>\n",
       "      <td>Izvestia’s sources in the ONF note that the re...</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>На древней Венере могли существовать океаны.</td>\n",
       "      <td>On the ancient Venus could exist in the oceans.</td>\n",
       "      <td>Oceans could have existed on ancient Venus.</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>До этого момента убийства оставались лишь исто...</td>\n",
       "      <td>Up to this point, the murders were just a stor...</td>\n",
       "      <td>Up until this point, the murders have remained...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Через полчаса обуглившийся клубень достают и п...   \n",
       "1  Здесь никто не думает отменять смертную казнь,...   \n",
       "2  Собеседники \"Известий\" в ОНФ отмечают, что док...   \n",
       "3       На древней Венере могли существовать океаны.   \n",
       "4  До этого момента убийства оставались лишь исто...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  After half an hour, the charred tuber is taken...   \n",
       "1  Here, no one thinks to abolish the death penal...   \n",
       "2  The interlocutors of\" Izvestiya \"in the onf no...   \n",
       "3    On the ancient Venus could exist in the oceans.   \n",
       "4  Up to this point, the murders were just a stor...   \n",
       "\n",
       "                                         translation  predicted_score  \n",
       "0  After half-an-hour, the charred tuber is retri...         0.800000  \n",
       "1  Here, no one is concerned with abolishing the ...         0.800000  \n",
       "2  Izvestia’s sources in the ONF note that the re...         0.625000  \n",
       "3        Oceans could have existed on ancient Venus.         0.428571  \n",
       "4  Up until this point, the murders have remained...         0.500000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Das Publikum ist fast gleichmäßig zwischen Sch...</td>\n",
       "      <td>The audience is almost evenly split between bl...</td>\n",
       "      <td>The audience is almost evenly split between bl...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Du kannst ihre Energie durch den Bildschirm sp...</td>\n",
       "      <td>You can feel their energy through the screen. \"\"</td>\n",
       "      <td>You can feel her energy through the screen.\"</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Da die Adresse unbekannt ist, wird die Mithilf...</td>\n",
       "      <td>As the address is unknown, the help of the pop...</td>\n",
       "      <td>As the address is unknown, the assistance of t...</td>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsenal-Manager Arsene Wenger, dessen Verein i...</td>\n",
       "      <td>Arsenal manager Arsene Wenger, whose club is o...</td>\n",
       "      <td>Arsenal manager Arsene Wenger, whose club is o...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Landwirtschaftsminister im Interview - Wie sch...</td>\n",
       "      <td>Agriculture Minister in the interview - How do...</td>\n",
       "      <td>Minister of Agriculture in interview – How do ...</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Das Publikum ist fast gleichmäßig zwischen Sch...   \n",
       "1  Du kannst ihre Energie durch den Bildschirm sp...   \n",
       "2  Da die Adresse unbekannt ist, wird die Mithilf...   \n",
       "3  Arsenal-Manager Arsene Wenger, dessen Verein i...   \n",
       "4  Landwirtschaftsminister im Interview - Wie sch...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  The audience is almost evenly split between bl...   \n",
       "1   You can feel their energy through the screen. \"\"   \n",
       "2  As the address is unknown, the help of the pop...   \n",
       "3  Arsenal manager Arsene Wenger, whose club is o...   \n",
       "4  Agriculture Minister in the interview - How do...   \n",
       "\n",
       "                                         translation  predicted_score  \n",
       "0  The audience is almost evenly split between bl...         1.000000  \n",
       "1       You can feel her energy through the screen.\"         0.875000  \n",
       "2  As the address is unknown, the assistance of t...         0.903226  \n",
       "3  Arsenal manager Arsene Wenger, whose club is o...         1.000000  \n",
       "4  Minister of Agriculture in interview – How do ...         0.733333  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Památník, důstojné pietní místo, stojí vůlí dě...</td>\n",
       "      <td>The monument, a dignified piecemeal place, sta...</td>\n",
       "      <td>The memorial, a solemn place of commemoration,...</td>\n",
       "      <td>0.522727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pracovník centra Čang Č-čung sdělil agentuře N...</td>\n",
       "      <td>Centre worker Zhang Zu-chung told the New Chin...</td>\n",
       "      <td>Centre worker Chang Chi-Chung told New China t...</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Veterináři nicméně odeberou namátkové vzorky v...</td>\n",
       "      <td>However, veterinarians take random samples of ...</td>\n",
       "      <td>However, veterinarians are taking samples of e...</td>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uživatel @TheePharoah jí neustále retweetoval ...</td>\n",
       "      <td>User @ TheePharoah constantly retweeted her po...</td>\n",
       "      <td>A user with the handle @TheePharoah was being ...</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lucii bylo tehdy pouhých 19 let a rozhodně net...</td>\n",
       "      <td>Lucia was only 19 at the time and certainly ha...</td>\n",
       "      <td>At that time, Lucie was only 19 years old, and...</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Památník, důstojné pietní místo, stojí vůlí dě...   \n",
       "1  Pracovník centra Čang Č-čung sdělil agentuře N...   \n",
       "2  Veterináři nicméně odeberou namátkové vzorky v...   \n",
       "3  Uživatel @TheePharoah jí neustále retweetoval ...   \n",
       "4  Lucii bylo tehdy pouhých 19 let a rozhodně net...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  The monument, a dignified piecemeal place, sta...   \n",
       "1  Centre worker Zhang Zu-chung told the New Chin...   \n",
       "2  However, veterinarians take random samples of ...   \n",
       "3  User @ TheePharoah constantly retweeted her po...   \n",
       "4  Lucia was only 19 at the time and certainly ha...   \n",
       "\n",
       "                                         translation  predicted_score  \n",
       "0  The memorial, a solemn place of commemoration,...         0.522727  \n",
       "1  Centre worker Chang Chi-Chung told New China t...         0.625000  \n",
       "2  However, veterinarians are taking samples of e...         0.593750  \n",
       "3  A user with the handle @TheePharoah was being ...         0.384615  \n",
       "4  At that time, Lucie was only 19 years old, and...         0.285714  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>已经批准筹建的，暂停批准开业</td>\n",
       "      <td>Where the preparation has been approved, the a...</td>\n",
       "      <td>Approval of opening on these establishments wi...</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>王丰源在首发式发言中说，来美国前想找本书看看别人的经验，但他翻遍新华书店没找到关于留学美国中...</td>\n",
       "      <td>In his opening speech, Mr. Wang said he wanted...</td>\n",
       "      <td>Wang Fengyuan spoke at the launch of his new b...</td>\n",
       "      <td>0.509804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“如果你不致力于创造透明文化，你会失去人才，”维特拉诺说道。</td>\n",
       "      <td>\"if you're not committed to creating a culture...</td>\n",
       "      <td>\"If you're not committed to creating a culture...</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>不过前提是多国联军先停止对也门的袭击。</td>\n",
       "      <td>The premise, however, is that the coalition fo...</td>\n",
       "      <td>However, the premise is that the multinational...</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“在此之前，我和前男友住在骑士桥的一个更大的房子里，”乔安妮说道。</td>\n",
       "      <td>\"before that, my ex and I lived in a bigger ho...</td>\n",
       "      <td>\"Before this, I was living with my ex in Knigh...</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0                                     已经批准筹建的，暂停批准开业   \n",
       "1  王丰源在首发式发言中说，来美国前想找本书看看别人的经验，但他翻遍新华书店没找到关于留学美国中...   \n",
       "2                     “如果你不致力于创造透明文化，你会失去人才，”维特拉诺说道。   \n",
       "3                                不过前提是多国联军先停止对也门的袭击。   \n",
       "4                  “在此之前，我和前男友住在骑士桥的一个更大的房子里，”乔安妮说道。   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Where the preparation has been approved, the a...   \n",
       "1  In his opening speech, Mr. Wang said he wanted...   \n",
       "2  \"if you're not committed to creating a culture...   \n",
       "3  The premise, however, is that the coalition fo...   \n",
       "4  \"before that, my ex and I lived in a bigger ho...   \n",
       "\n",
       "                                         translation  predicted_score  \n",
       "0  Approval of opening on these establishments wi...         0.555556  \n",
       "1  Wang Fengyuan spoke at the launch of his new b...         0.509804  \n",
       "2  \"If you're not committed to creating a culture...         0.789474  \n",
       "3  However, the premise is that the multinational...         0.800000  \n",
       "4  \"Before this, I was living with my ex in Knigh...         0.647059  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The future and the destinies of the citizens o...</td>\n",
       "      <td>世界上每个国家公民的未来和命运日益联系在一起。</td>\n",
       "      <td>世界各国人民前途命运越来越紧密地联系在一起。</td>\n",
       "      <td>0.268354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>After all that hard work, the finished result ...</td>\n",
       "      <td>经过那么多的努力，最终的结果现在已经可以揭晓了。</td>\n",
       "      <td>经过这么艰辛的工作，最终的结果现在才得以公布。</td>\n",
       "      <td>0.339510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Author: researcher of Suning Institute of Fina...</td>\n",
       "      <td>作者：苏宁金融研究所研究员，财经专栏作家，财经评论员。</td>\n",
       "      <td>作者：苏宁金融研究院特约研究员，财经专栏作家，财经评论员。</td>\n",
       "      <td>0.833079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“The Great Wall” tells the story of a Chinese ...</td>\n",
       "      <td>《长城》讲述了古代一支中国精锐部队在世界著名的中国长城上与怪物桃蒂英勇作战的故事。</td>\n",
       "      <td>《长城》讲述了在古代，一支中国精英部队为保卫人类，在举世闻名的长城上与怪兽饕餮进行生死决战的故事。</td>\n",
       "      <td>0.365893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Our comrades from the Political Bureau should ...</td>\n",
       "      <td>政治局同志要学习历史，讲道理，不能混淆公、私利益，叫白黑，模糊义与利的界限，处理基于裙带关系...</td>\n",
       "      <td>中央政治局的同志都应该明史知理，不能颠倒了公私、混淆了是非、模糊了义利、放纵了亲情，要带头树...</td>\n",
       "      <td>0.150515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  The future and the destinies of the citizens o...   \n",
       "1  After all that hard work, the finished result ...   \n",
       "2  Author: researcher of Suning Institute of Fina...   \n",
       "3  “The Great Wall” tells the story of a Chinese ...   \n",
       "4  Our comrades from the Political Bureau should ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0                            世界上每个国家公民的未来和命运日益联系在一起。   \n",
       "1                           经过那么多的努力，最终的结果现在已经可以揭晓了。   \n",
       "2                        作者：苏宁金融研究所研究员，财经专栏作家，财经评论员。   \n",
       "3          《长城》讲述了古代一支中国精锐部队在世界著名的中国长城上与怪物桃蒂英勇作战的故事。   \n",
       "4  政治局同志要学习历史，讲道理，不能混淆公、私利益，叫白黑，模糊义与利的界限，处理基于裙带关系...   \n",
       "\n",
       "                                         translation  predicted_score  \n",
       "0                             世界各国人民前途命运越来越紧密地联系在一起。         0.268354  \n",
       "1                            经过这么艰辛的工作，最终的结果现在才得以公布。         0.339510  \n",
       "2                      作者：苏宁金融研究院特约研究员，财经专栏作家，财经评论员。         0.833079  \n",
       "3  《长城》讲述了在古代，一支中国精英部队为保卫人类，在举世闻名的长城上与怪兽饕餮进行生死决战的故事。         0.365893  \n",
       "4  中央政治局的同志都应该明史知理，不能颠倒了公私、混淆了是非、模糊了义利、放纵了亲情，要带头树...         0.150515  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One local resident who did not wish to be name...</td>\n",
       "      <td>Eräs paikallinen asukas, joka ei halunnut nime...</td>\n",
       "      <td>Toisen nimettömänä pysyttelevän asukkaan mukaa...</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Still, she clings to a chant she's committed t...</td>\n",
       "      <td>Silti hän takertuu chant hän on sitoutunut mui...</td>\n",
       "      <td>Silti hän luottaa edelleen iskulauseeseen, jon...</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't want to be asked, 'What were you doing...</td>\n",
       "      <td>En halua, että minulta kysytään: \"Mitä te teit...</td>\n",
       "      <td>En halua, että kenenkään tarvitsee kysyä minul...</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I wouldn't say it was a lie – that's a pretty...</td>\n",
       "      <td>\"En sanoisi, että se oli valhe - se on aika ro...</td>\n",
       "      <td>En sanoisi, että se oli valhe, se on aika kova...</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kari Kola took part in the opening ceremony of...</td>\n",
       "      <td>Kari Kola osallistui valon vuoden avajaisiin v...</td>\n",
       "      <td>Kari Kola oli mukana Valon teemavuoden avajais...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  One local resident who did not wish to be name...   \n",
       "1  Still, she clings to a chant she's committed t...   \n",
       "2  I don't want to be asked, 'What were you doing...   \n",
       "3  \"I wouldn't say it was a lie – that's a pretty...   \n",
       "4  Kari Kola took part in the opening ceremony of...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Eräs paikallinen asukas, joka ei halunnut nime...   \n",
       "1  Silti hän takertuu chant hän on sitoutunut mui...   \n",
       "2  En halua, että minulta kysytään: \"Mitä te teit...   \n",
       "3  \"En sanoisi, että se oli valhe - se on aika ro...   \n",
       "4  Kari Kola osallistui valon vuoden avajaisiin v...   \n",
       "\n",
       "                                         translation  predicted_score  \n",
       "0  Toisen nimettömänä pysyttelevän asukkaan mukaa...         0.250000  \n",
       "1  Silti hän luottaa edelleen iskulauseeseen, jon...         0.625000  \n",
       "2  En halua, että kenenkään tarvitsee kysyä minul...         0.363636  \n",
       "3  En sanoisi, että se oli valhe, se on aika kova...         0.916667  \n",
       "4  Kari Kola oli mukana Valon teemavuoden avajais...         0.500000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for element in [ru_en_test, de_en_test, cs_en_test, zh_en_test, en_zh_test, en_fi_test]:\n",
    "    display(element.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-czech",
   "metadata": {},
   "source": [
    "## LINEAR REGRESSION ON RESPECTIVE TOP METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "organizational-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dense-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_corpus = \"/Users/franz/Desktop/TM Project/corpus/\"\n",
    "\n",
    "ru_en = pd.read_csv(path_corpus + \"ru-en/scores.csv\")\n",
    "de_en = pd.read_csv(path_corpus + \"de-en/scores.csv\")\n",
    "cs_en = pd.read_csv(path_corpus + \"cs-en/scores.csv\")\n",
    "zh_en = pd.read_csv(path_corpus + \"zh-en/scores.csv\")\n",
    "en_zh = pd.read_csv(path_corpus + \"en-zh/scores.csv\")\n",
    "en_fi = pd.read_csv(path_corpus + \"en-fi/scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "smaller-bubble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE L Precision Pearson</th>\n",
       "      <td>0.355554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Fmeasure Pearson</th>\n",
       "      <td>0.352986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Precision Pearson</th>\n",
       "      <td>0.344109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Fmeasure Pearson</th>\n",
       "      <td>0.341309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU Star Pearson</th>\n",
       "      <td>0.333658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Russian into English\n",
       "ROUGE L Precision Pearson              0.355554\n",
       "ROUGE L Fmeasure Pearson               0.352986\n",
       "ROUGE 1 Precision Pearson              0.344109\n",
       "ROUGE 1 Fmeasure Pearson               0.341309\n",
       "BLEU Star Pearson                      0.333658"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>German into English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE L Fmeasure Pearson</th>\n",
       "      <td>0.327532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Fmeasure Pearson</th>\n",
       "      <td>0.326557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Precision Pearson</th>\n",
       "      <td>0.321503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Precision Pearson</th>\n",
       "      <td>0.316624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Fmeasure Pearson</th>\n",
       "      <td>0.301592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           German into English\n",
       "ROUGE L Fmeasure Pearson              0.327532\n",
       "ROUGE 1 Fmeasure Pearson              0.326557\n",
       "ROUGE L Precision Pearson             0.321503\n",
       "ROUGE 1 Precision Pearson             0.316624\n",
       "ROUGE 2 Fmeasure Pearson              0.301592"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Czech into English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE L Precision Pearson</th>\n",
       "      <td>0.470087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Fmeasure Pearson</th>\n",
       "      <td>0.461447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Precision Pearson</th>\n",
       "      <td>0.456718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Fmeasure Pearson</th>\n",
       "      <td>0.450511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU Star Pearson</th>\n",
       "      <td>0.425182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Czech into English\n",
       "ROUGE L Precision Pearson            0.470087\n",
       "ROUGE L Fmeasure Pearson             0.461447\n",
       "ROUGE 1 Precision Pearson            0.456718\n",
       "ROUGE 1 Fmeasure Pearson             0.450511\n",
       "BLEU Star Pearson                    0.425182"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chinese into English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE L Precision Pearson</th>\n",
       "      <td>0.347083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Fmeasure Pearson</th>\n",
       "      <td>0.344989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Precision Pearson</th>\n",
       "      <td>0.331985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Fmeasure Pearson</th>\n",
       "      <td>0.328195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU Star Pearson</th>\n",
       "      <td>0.313196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Chinese into English\n",
       "ROUGE L Precision Pearson              0.347083\n",
       "ROUGE L Fmeasure Pearson               0.344989\n",
       "ROUGE 1 Precision Pearson              0.331985\n",
       "ROUGE 1 Fmeasure Pearson               0.328195\n",
       "BLEU Star Pearson                      0.313196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English into Chinese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLEU Corpus Pearson</th>\n",
       "      <td>0.424316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Fmeasure Pearson</th>\n",
       "      <td>0.095062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Recall Pearson</th>\n",
       "      <td>0.092338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Precision Pearson</th>\n",
       "      <td>0.088139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Fmeasure Pearson</th>\n",
       "      <td>0.082974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           English into Chinese\n",
       "BLEU Corpus Pearson                    0.424316\n",
       "ROUGE 2 Fmeasure Pearson               0.095062\n",
       "ROUGE 2 Recall Pearson                 0.092338\n",
       "ROUGE 2 Precision Pearson              0.088139\n",
       "ROUGE L Fmeasure Pearson               0.082974"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English into Finish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Precision Pearson</th>\n",
       "      <td>0.549302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Fmeasure Pearson</th>\n",
       "      <td>0.544540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Precision Pearson</th>\n",
       "      <td>0.540008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Fmeasure Pearson</th>\n",
       "      <td>0.535137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Recall Pearson</th>\n",
       "      <td>0.513220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           English into Finish\n",
       "ROUGE 1 Precision Pearson             0.549302\n",
       "ROUGE 1 Fmeasure Pearson              0.544540\n",
       "ROUGE L Precision Pearson             0.540008\n",
       "ROUGE L Fmeasure Pearson              0.535137\n",
       "ROUGE 1 Recall Pearson                0.513220"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#top 3 metrics by language pair\n",
    "for i in range(6):\n",
    "    display(pd.DataFrame(pearson_df.iloc[:,i].sort_values(ascending = False).head(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-proof",
   "metadata": {},
   "source": [
    "### Russian into English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "rural-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_precision = []\n",
    "l_fmeasure = []\n",
    "precision_1 = []\n",
    "fmeasure_1 = []\n",
    "bleu_star = []\n",
    "\n",
    "for i in range(ru_en.shape[0]):\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL', 'rouge1'], use_stemmer=True)\n",
    "    scores = scorer.score(ru_en.loc[i,\"reference\"], ru_en.loc[i,\"translation\"])\n",
    "    l_precision.append(scores[\"rougeL\"].precision)\n",
    "    l_fmeasure.append(scores[\"rougeL\"].fmeasure)\n",
    "    precision_1.append(scores[\"rouge1\"].precision)\n",
    "    fmeasure_1.append(scores[\"rouge1\"].fmeasure)\n",
    "\n",
    "    reference = ru_en.loc[i,\"reference\"]\n",
    "    translation = ru_en.loc[i,\"translation\"]\n",
    "    bleu_star.append(BLEU_star_compact(reference, translation))\n",
    "    \n",
    "ru_en[\"l_precision\"] = l_precision\n",
    "ru_en[\"l_fmeasure\"] = l_fmeasure\n",
    "ru_en[\"precision_1\"] = precision_1\n",
    "ru_en[\"fmeasure_1\"] = fmeasure_1\n",
    "ru_en[\"bleu_star\"] = bleu_star\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "conceptual-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_en_scores = ru_en[[\"l_precision\", \"l_fmeasure\", \"precision_1\", \"fmeasure_1\", \"bleu_star\", \"z-score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "moral-folder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-06b3833df17d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ru_en_scores[element] = zscore(ru_en_scores[element])\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "for element in [\"l_precision\", \"l_fmeasure\", \"precision_1\", \"fmeasure_1\", \"bleu_star\"]:\n",
    "    ru_en_scores[element] = zscore(ru_en_scores[element])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dried-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_en_train = ru_en_scores.iloc[:int(ru_en_scores.shape[0]*0.7),:]\n",
    "ru_en_test = ru_en_scores.iloc[int(ru_en_scores.shape[0]*0.7):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "tender-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = ru_en_train.iloc[:,:-1]\n",
    "Y = ru_en_train.iloc[:,-1]\n",
    "X_test = ru_en_test.iloc[:,:-1]\n",
    "Y_test = ru_en_test.iloc[:,-1]\n",
    "\n",
    "model_ru_en = LinearRegression()\n",
    "model_ru_en.fit(X,Y)\n",
    "\n",
    "result = pd.DataFrame(Y_test)\n",
    "result[\"regression_values\"] = model_ru_en.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "allied-limit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z-score</th>\n",
       "      <th>regression_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.362087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_values</th>\n",
       "      <td>0.362087</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    z-score  regression_values\n",
       "z-score            1.000000           0.362087\n",
       "regression_values  0.362087           1.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-drunk",
   "metadata": {},
   "source": [
    "### German into English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "impressive-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-35dfc71f3961>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  de_en_scores[element] = zscore(de_en_scores[element])\n"
     ]
    }
   ],
   "source": [
    "l_fmeasure = []\n",
    "fmeasure_1 = []\n",
    "l_precision = []\n",
    "l_recall = []\n",
    "precision_1 = []\n",
    "\n",
    "\n",
    "for i in range(de_en.shape[0]):\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL', 'rouge1'], use_stemmer=True)\n",
    "    scores = scorer.score(de_en.loc[i,\"reference\"], de_en.loc[i,\"translation\"])\n",
    "    l_fmeasure.append(scores[\"rougeL\"].fmeasure)\n",
    "    fmeasure_1.append(scores[\"rouge1\"].fmeasure)\n",
    "    l_precision.append(scores[\"rougeL\"].precision)\n",
    "    l_recall.append(scores[\"rougeL\"].recall)\n",
    "    precision_1.append(scores[\"rouge1\"].precision)\n",
    "    \n",
    "de_en[\"l_fmeasure\"] = l_fmeasure\n",
    "de_en[\"fmeasure_1\"] = fmeasure_1\n",
    "de_en[\"l_precision\"] = l_precision\n",
    "de_en[\"l_recall\"] = l_recall\n",
    "de_en[\"precision_1\"] = precision_1\n",
    "\n",
    "de_en_scores = de_en[[\"l_fmeasure\", \"fmeasure_1\", \"l_precision\", \"l_recall\", \"precision_1\", \"z-score\"]]\n",
    "\n",
    "for element in [\"l_fmeasure\", \"fmeasure_1\", \"l_precision\", \"l_recall\", \"precision_1\"]:\n",
    "    de_en_scores[element] = zscore(de_en_scores[element])\n",
    "    \n",
    "de_en_train = de_en_scores.iloc[:int(de_en_scores.shape[0]*0.7),:]\n",
    "de_en_test = de_en_scores.iloc[int(de_en_scores.shape[0]*0.7):,:]\n",
    "\n",
    "X = de_en_train.iloc[:,:-1]\n",
    "Y = de_en_train.iloc[:,-1]\n",
    "X_test = de_en_test.iloc[:,:-1]\n",
    "Y_test = de_en_test.iloc[:,-1]\n",
    "\n",
    "model_de_en = LinearRegression()\n",
    "model_de_en.fit(X,Y)\n",
    "\n",
    "result = pd.DataFrame(Y_test)\n",
    "result[\"regression_values\"] = model_de_en.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "wrapped-password",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-35dfc71f3961>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  de_en_scores[element] = zscore(de_en_scores[element])\n"
     ]
    }
   ],
   "source": [
    "l_fmeasure = []\n",
    "fmeasure_1 = []\n",
    "l_precision = []\n",
    "l_recall = []\n",
    "precision_1 = []\n",
    "\n",
    "\n",
    "for i in range(de_en.shape[0]):\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL', 'rouge1'], use_stemmer=True)\n",
    "    scores = scorer.score(de_en.loc[i,\"reference\"], de_en.loc[i,\"translation\"])\n",
    "    l_fmeasure.append(scores[\"rougeL\"].fmeasure)\n",
    "    fmeasure_1.append(scores[\"rouge1\"].fmeasure)\n",
    "    l_precision.append(scores[\"rougeL\"].precision)\n",
    "    l_recall.append(scores[\"rougeL\"].recall)\n",
    "    precision_1.append(scores[\"rouge1\"].precision)\n",
    "    \n",
    "de_en[\"l_fmeasure\"] = l_fmeasure\n",
    "de_en[\"fmeasure_1\"] = fmeasure_1\n",
    "de_en[\"l_precision\"] = l_precision\n",
    "de_en[\"l_recall\"] = l_recall\n",
    "de_en[\"precision_1\"] = precision_1\n",
    "\n",
    "de_en_scores = de_en[[\"l_fmeasure\", \"fmeasure_1\", \"l_precision\", \"l_recall\", \"precision_1\", \"z-score\"]]\n",
    "\n",
    "for element in [\"l_fmeasure\", \"fmeasure_1\", \"l_precision\", \"l_recall\", \"precision_1\"]:\n",
    "    de_en_scores[element] = zscore(de_en_scores[element])\n",
    "    \n",
    "de_en_train = de_en_scores.iloc[:int(de_en_scores.shape[0]*0.7),:]\n",
    "de_en_test = de_en_scores.iloc[int(de_en_scores.shape[0]*0.7):,:]\n",
    "\n",
    "X = de_en_train.iloc[:,:-1]\n",
    "Y = de_en_train.iloc[:,-1]\n",
    "X_test = de_en_test.iloc[:,:-1]\n",
    "Y_test = de_en_test.iloc[:,-1]\n",
    "\n",
    "model_de_en = LinearRegression()\n",
    "model_de_en.fit(X,Y)\n",
    "\n",
    "result = pd.DataFrame(Y_test)\n",
    "result[\"regression_values\"] = model_de_en.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "reported-assumption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z-score</th>\n",
       "      <th>regression_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.324474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_values</th>\n",
       "      <td>0.324474</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    z-score  regression_values\n",
       "z-score            1.000000           0.324474\n",
       "regression_values  0.324474           1.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-uncertainty",
   "metadata": {},
   "source": [
    "### Czech into English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "tested-samuel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-4cd61afd8f67>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cs_en_scores[element] = zscore(cs_en_scores[element])\n"
     ]
    }
   ],
   "source": [
    "l_precision = []\n",
    "l_fmeasure = []\n",
    "precision_1 = []\n",
    "fmeasure_1 = []\n",
    "bleu_star = []\n",
    "\n",
    "for i in range(cs_en.shape[0]):\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL', 'rouge1'], use_stemmer=True)\n",
    "    scores = scorer.score(cs_en.loc[i,\"reference\"], cs_en.loc[i,\"translation\"])\n",
    "    l_precision.append(scores[\"rougeL\"].precision)\n",
    "    l_fmeasure.append(scores[\"rougeL\"].fmeasure)\n",
    "    precision_1.append(scores[\"rouge1\"].precision)\n",
    "    fmeasure_1.append(scores[\"rouge1\"].fmeasure)\n",
    "\n",
    "    reference = cs_en.loc[i,\"reference\"]\n",
    "    translation = cs_en.loc[i,\"translation\"]\n",
    "    bleu_star.append(BLEU_star_compact(reference, translation))\n",
    "    \n",
    "cs_en[\"l_precision\"] = l_precision\n",
    "cs_en[\"l_fmeasure\"] = l_fmeasure\n",
    "cs_en[\"precision_1\"] = precision_1\n",
    "cs_en[\"fmeasure_1\"] = fmeasure_1\n",
    "cs_en[\"bleu_star\"] = bleu_star\n",
    "\n",
    "cs_en_scores = cs_en[[\"l_precision\", \"l_fmeasure\", \"precision_1\", \"fmeasure_1\", \"bleu_star\", \"z-score\"]]\n",
    "\n",
    "for element in [\"l_precision\", \"l_fmeasure\", \"precision_1\", \"fmeasure_1\", \"bleu_star\"]:\n",
    "    cs_en_scores[element] = zscore(cs_en_scores[element])\n",
    "    \n",
    "cs_en_train = cs_en_scores.iloc[:int(cs_en_scores.shape[0]*0.7),:]\n",
    "cs_en_test = cs_en_scores.iloc[int(cs_en_scores.shape[0]*0.7):,:]\n",
    "\n",
    "X = cs_en_train.iloc[:,:-1]\n",
    "Y = cs_en_train.iloc[:,-1]\n",
    "X_test = cs_en_test.iloc[:,:-1]\n",
    "Y_test = cs_en_test.iloc[:,-1]\n",
    "X_full = cs_en_scores.iloc[:,:-1]\n",
    "Y_full = cs_en_scores.iloc[:,-1]\n",
    "\n",
    "model_cs_en = LinearRegression()\n",
    "model_cs_en.fit(X,Y)\n",
    "\n",
    "result = pd.DataFrame(Y_test)\n",
    "result[\"regression_values\"] = model_cs_en.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "weird-crowd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z-score</th>\n",
       "      <th>regression_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.48009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_values</th>\n",
       "      <td>0.48009</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   z-score  regression_values\n",
       "z-score            1.00000            0.48009\n",
       "regression_values  0.48009            1.00000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-vacuum",
   "metadata": {},
   "source": [
    "### Chinese into English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "together-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-55c1addaa37c>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  zh_en_scores[element] = zscore(zh_en_scores[element])\n"
     ]
    }
   ],
   "source": [
    "l_precision = []\n",
    "l_fmeasure = []\n",
    "precision_1 = []\n",
    "fmeasure_1 = []\n",
    "bleu_star = []\n",
    "\n",
    "for i in range(zh_en.shape[0]):\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL', 'rouge1'], use_stemmer=True)\n",
    "    scores = scorer.score(zh_en.loc[i,\"reference\"], zh_en.loc[i,\"translation\"])\n",
    "    l_precision.append(scores[\"rougeL\"].precision)\n",
    "    l_fmeasure.append(scores[\"rougeL\"].fmeasure)\n",
    "    precision_1.append(scores[\"rouge1\"].precision)\n",
    "    fmeasure_1.append(scores[\"rouge1\"].fmeasure)\n",
    "\n",
    "    reference = zh_en.loc[i,\"reference\"]\n",
    "    translation = zh_en.loc[i,\"translation\"]\n",
    "    bleu_star.append(BLEU_star_compact(reference, translation))\n",
    "    \n",
    "zh_en[\"l_precision\"] = l_precision\n",
    "zh_en[\"l_fmeasure\"] = l_fmeasure\n",
    "zh_en[\"precision_1\"] = precision_1\n",
    "zh_en[\"fmeasure_1\"] = fmeasure_1\n",
    "zh_en[\"bleu_star\"] = bleu_star\n",
    "\n",
    "zh_en_scores = zh_en[[\"l_precision\", \"l_fmeasure\", \"precision_1\", \"fmeasure_1\", \"bleu_star\", \"z-score\"]]\n",
    "\n",
    "for element in [\"l_precision\", \"l_fmeasure\", \"precision_1\", \"fmeasure_1\", \"bleu_star\"]:\n",
    "    zh_en_scores[element] = zscore(zh_en_scores[element])\n",
    "    \n",
    "zh_en_train = zh_en_scores.iloc[:int(zh_en_scores.shape[0]*0.7),:]\n",
    "zh_en_test = zh_en_scores.iloc[int(zh_en_scores.shape[0]*0.7):,:]\n",
    "\n",
    "X = zh_en_train.iloc[:,:-1]\n",
    "Y = zh_en_train.iloc[:,-1]\n",
    "X_test = zh_en_test.iloc[:,:-1]\n",
    "Y_test = zh_en_test.iloc[:,-1]\n",
    "\n",
    "model_zh_en = LinearRegression()\n",
    "model_zh_en.fit(X,Y)\n",
    "\n",
    "result = pd.DataFrame(Y_test)\n",
    "result[\"regression_values\"] = model_zh_en.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "prospective-fossil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z-score</th>\n",
       "      <th>regression_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.353457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_values</th>\n",
       "      <td>0.353457</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    z-score  regression_values\n",
       "z-score            1.000000           0.353457\n",
       "regression_values  0.353457           1.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-coaching",
   "metadata": {},
   "source": [
    "### English into Chinese "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-musician",
   "metadata": {},
   "source": [
    "As only the BLEU Corpus yields acceptable results, there's no need for a Regression for this language pair!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-accuracy",
   "metadata": {},
   "source": [
    "### English into Finish "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ultimate-spotlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-9d10d838c765>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  en_fi_scores[element] = zscore(en_fi_scores[element])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "l_fmeasure = []\n",
    "fmeasure_1 = []\n",
    "l_precision = []\n",
    "recall_1 = []\n",
    "precision_1 = []\n",
    "\n",
    "\n",
    "for i in range(en_fi.shape[0]):\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL', 'rouge1'], use_stemmer=True)\n",
    "    scores = scorer.score(en_fi.loc[i,\"reference\"], en_fi.loc[i,\"translation\"])\n",
    "    l_fmeasure.append(scores[\"rougeL\"].fmeasure)\n",
    "    fmeasure_1.append(scores[\"rouge1\"].fmeasure)\n",
    "    l_precision.append(scores[\"rougeL\"].precision)\n",
    "    recall_1.append(scores[\"rouge1\"].recall)\n",
    "    precision_1.append(scores[\"rouge1\"].precision)\n",
    "    \n",
    "en_fi[\"l_fmeasure\"] = l_fmeasure\n",
    "en_fi[\"fmeasure_1\"] = fmeasure_1\n",
    "en_fi[\"l_precision\"] = l_precision\n",
    "en_fi[\"recall_1\"] = recall_1\n",
    "en_fi[\"precision_1\"] = precision_1\n",
    "\n",
    "en_fi_scores = en_fi[[\"l_fmeasure\", \"fmeasure_1\", \"l_precision\", \"recall_1\", \"precision_1\", \"z-score\"]]\n",
    "\n",
    "for element in [\"l_fmeasure\", \"fmeasure_1\", \"l_precision\", \"recall_1\", \"precision_1\"]:\n",
    "    en_fi_scores[element] = zscore(en_fi_scores[element])\n",
    "    \n",
    "en_fi_train = en_fi_scores.iloc[:int(en_fi_scores.shape[0]*0.7),:]\n",
    "en_fi_test = en_fi_scores.iloc[int(en_fi_scores.shape[0]*0.7):,:]\n",
    "\n",
    "X = en_fi_train.iloc[:,:-1]\n",
    "Y = en_fi_train.iloc[:,-1]\n",
    "X_test = en_fi_test.iloc[:,:-1]\n",
    "Y_test = en_fi_test.iloc[:,-1]\n",
    "\n",
    "model_en_fi = LinearRegression()\n",
    "model_en_fi.fit(X,Y)\n",
    "\n",
    "result = pd.DataFrame(Y_test)\n",
    "result[\"regression_values\"] = model_en_fi.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "electoral-blind",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z-score</th>\n",
       "      <th>regression_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_values</th>\n",
       "      <td>0.458622</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    z-score  regression_values\n",
       "z-score            1.000000           0.458622\n",
       "regression_values  0.458622           1.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-passage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "funky-approach",
   "metadata": {},
   "source": [
    "# REGRESSION ON TOP OF ALL LEXICAL METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-forth",
   "metadata": {},
   "source": [
    "### RU EN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "corporate-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_en_ = ru_en_.drop(columns=[\"source\", \"reference\", \"translation\", \"avg-score\", \"annotators\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "anonymous-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in ['BLEU', 'BLEU_s', 'BLEU_c', 'ROUGE1_precision', 'ROUGE1_recall', 'ROUGE1_fmeasure', 'ROUGE2_precision', 'ROUGE2_recall', 'ROUGE2_fmeasure', 'ROUGEL_precision', 'ROUGEL_recall', 'ROUGEL_fmeasure']:\n",
    "    ru_en_[element] = zscore(ru_en_[element])\n",
    "    \n",
    "ru_en__train = ru_en_.iloc[:int(ru_en_.shape[0]*0.7),:]\n",
    "ru_en__test = ru_en_.iloc[int(ru_en_.shape[0]*0.7):,:]\n",
    "\n",
    "X = ru_en__train.iloc[:,1:]\n",
    "Y = ru_en__train.iloc[:,0]\n",
    "X_test = ru_en__test.iloc[:,1:]\n",
    "Y_test = ru_en__test.iloc[:,0] \n",
    "X_full = ru_en_.iloc[:,1:]\n",
    "Y_full = ru_en_.iloc[:,0] \n",
    "\n",
    "model_ru_en_ = LinearRegression()\n",
    "model_ru_en_.fit(X,Y)\n",
    "\n",
    "final_model_ru_en = LinearRegression()\n",
    "final_model_ru_en.fit(X_full, Y_full)\n",
    "    \n",
    "result = pd.DataFrame(Y_test)\n",
    "result[\"regression_values\"] = model_ru_en_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "approved-protein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z-score</th>\n",
       "      <th>regression_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_values</th>\n",
       "      <td>0.368027</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    z-score  regression_values\n",
       "z-score            1.000000           0.368027\n",
       "regression_values  0.368027           1.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-graham",
   "metadata": {},
   "source": [
    "### DE EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cheap-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_en_ = de_en_.drop(columns=[\"source\", \"reference\", \"translation\", \"avg-score\", \"annotators\"])\n",
    "\n",
    "for element in ['BLEU', 'BLEU_s', 'BLEU_c', 'ROUGE1_precision', 'ROUGE1_recall', 'ROUGE1_fmeasure', 'ROUGE2_precision', 'ROUGE2_recall', 'ROUGE2_fmeasure', 'ROUGEL_precision', 'ROUGEL_recall', 'ROUGEL_fmeasure']:\n",
    "    de_en_[element] = zscore(de_en_[element])\n",
    "    \n",
    "de_en__train = de_en_.iloc[:int(de_en_.shape[0]*0.7),:]\n",
    "de_en__test = de_en_.iloc[int(de_en_.shape[0]*0.7):,:]\n",
    "\n",
    "X = de_en__train.iloc[:,1:]\n",
    "Y = de_en__train.iloc[:,0]\n",
    "X_test = de_en__test.iloc[:,1:]\n",
    "Y_test = de_en__test.iloc[:,0] \n",
    "\n",
    "model_de_en_ = LinearRegression()\n",
    "model_de_en_.fit(X,Y)\n",
    "    \n",
    "result = pd.DataFrame(Y_test)\n",
    "result[\"regression_values\"] = model_de_en_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "magnetic-relative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z-score</th>\n",
       "      <th>regression_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_values</th>\n",
       "      <td>0.327479</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    z-score  regression_values\n",
       "z-score            1.000000           0.327479\n",
       "regression_values  0.327479           1.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-needle",
   "metadata": {},
   "source": [
    "### CS EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "shared-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_en_ = cs_en_.drop(columns=[\"source\", \"reference\", \"translation\", \"avg-score\", \"annotators\"])\n",
    "\n",
    "for element in ['BLEU', 'BLEU_s', 'BLEU_c', 'ROUGE1_precision', 'ROUGE1_recall', 'ROUGE1_fmeasure', 'ROUGE2_precision', 'ROUGE2_recall', 'ROUGE2_fmeasure', 'ROUGEL_precision', 'ROUGEL_recall', 'ROUGEL_fmeasure']:\n",
    "    cs_en_[element] = zscore(cs_en_[element])\n",
    "    \n",
    "cs_en__train = cs_en_.iloc[:int(cs_en_.shape[0]*0.7),:]\n",
    "cs_en__test = cs_en_.iloc[int(cs_en_.shape[0]*0.7):,:]\n",
    "\n",
    "X = cs_en__train.iloc[:,1:]\n",
    "Y = cs_en__train.iloc[:,0]\n",
    "X_test = cs_en__test.iloc[:,1:]\n",
    "Y_test = cs_en__test.iloc[:,0] \n",
    "X_full = cs_en_.iloc[:,1:]\n",
    "Y_full = cs_en_.iloc[:,0] \n",
    "\n",
    "model_cs_en_ = LinearRegression()\n",
    "model_cs_en_.fit(X,Y)\n",
    "\n",
    "final_model_cs_en = LinearRegression()\n",
    "final_model_cs_en.fit(X_full, Y_full)\n",
    "    \n",
    "result = pd.DataFrame(Y_test)\n",
    "result[\"regression_values\"] = model_cs_en_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "smaller-australia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z-score</th>\n",
       "      <th>regression_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_values</th>\n",
       "      <td>0.482638</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    z-score  regression_values\n",
       "z-score            1.000000           0.482638\n",
       "regression_values  0.482638           1.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-secretariat",
   "metadata": {},
   "source": [
    "### ZH EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "green-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_en_ = zh_en_.drop(columns=[\"source\", \"reference\", \"translation\", \"avg-score\", \"annotators\"])\n",
    "\n",
    "for element in ['BLEU', 'BLEU_s', 'BLEU_c', 'ROUGE1_precision', 'ROUGE1_recall', 'ROUGE1_fmeasure', 'ROUGE2_precision', 'ROUGE2_recall', 'ROUGE2_fmeasure', 'ROUGEL_precision', 'ROUGEL_recall', 'ROUGEL_fmeasure']:\n",
    "    zh_en_[element] = zscore(zh_en_[element])\n",
    "    \n",
    "zh_en__train = zh_en_.iloc[:int(zh_en_.shape[0]*0.7),:]\n",
    "zh_en__test = zh_en_.iloc[int(zh_en_.shape[0]*0.7):,:]\n",
    "\n",
    "X = zh_en__train.iloc[:,1:]\n",
    "Y = zh_en__train.iloc[:,0]\n",
    "X_test = zh_en__test.iloc[:,1:]\n",
    "Y_test = zh_en__test.iloc[:,0] \n",
    "X_full = zh_en_.iloc[:,1:]\n",
    "Y_full = zh_en_.iloc[:,0] \n",
    "\n",
    "model_zh_en_ = LinearRegression()\n",
    "model_zh_en_.fit(X,Y)\n",
    "\n",
    "final_model_zh_en = LinearRegression()\n",
    "final_model_zh_en.fit(X_full, Y_full)\n",
    "    \n",
    "result = pd.DataFrame(Y_test)\n",
    "result[\"regression_values\"] = model_zh_en_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "posted-problem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z-score</th>\n",
       "      <th>regression_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.360435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_values</th>\n",
       "      <td>0.360435</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    z-score  regression_values\n",
       "z-score            1.000000           0.360435\n",
       "regression_values  0.360435           1.000000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-ferry",
   "metadata": {},
   "source": [
    "### EN ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "distant-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_zh_ = en_zh_.drop(columns=[\"source\", \"reference\", \"translation\", \"avg-score\", \"annotators\"])\n",
    "\n",
    "for element in ['BLEU', 'BLEU_s', 'BLEU_c', 'ROUGE1_precision', 'ROUGE1_recall', 'ROUGE1_fmeasure', 'ROUGE2_precision', 'ROUGE2_recall', 'ROUGE2_fmeasure', 'ROUGEL_precision', 'ROUGEL_recall', 'ROUGEL_fmeasure']:\n",
    "    en_zh_[element] = zscore(en_zh_[element])\n",
    "    \n",
    "en_zh__train = en_zh_.iloc[:int(en_zh_.shape[0]*0.7),:]\n",
    "en_zh__test = en_zh_.iloc[int(en_zh_.shape[0]*0.7):,:]\n",
    "\n",
    "X = en_zh__train.iloc[:,1:]\n",
    "Y = en_zh__train.iloc[:,0]\n",
    "X_test = en_zh__test.iloc[:,1:]\n",
    "Y_test = en_zh__test.iloc[:,0] \n",
    "\n",
    "model_en_zh_ = LinearRegression()\n",
    "model_en_zh_.fit(X,Y)\n",
    "    \n",
    "result = pd.DataFrame(Y_test)\n",
    "result[\"regression_values\"] = model_en_zh_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "living-equipment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z-score</th>\n",
       "      <th>regression_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.41002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_values</th>\n",
       "      <td>0.41002</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   z-score  regression_values\n",
       "z-score            1.00000            0.41002\n",
       "regression_values  0.41002            1.00000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-swaziland",
   "metadata": {},
   "source": [
    "### EN FI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "hearing-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_fi_ = en_fi_.drop(columns=[\"source\", \"reference\", \"translation\", \"avg-score\", \"annotators\"])\n",
    "\n",
    "for element in ['BLEU', 'BLEU_s', 'BLEU_c', 'ROUGE1_precision', 'ROUGE1_recall', 'ROUGE1_fmeasure', 'ROUGE2_precision', 'ROUGE2_recall', 'ROUGE2_fmeasure', 'ROUGEL_precision', 'ROUGEL_recall', 'ROUGEL_fmeasure']:\n",
    "    en_fi_[element] = zscore(en_fi_[element])\n",
    "    \n",
    "en_fi__train = en_fi_.iloc[:int(en_fi_.shape[0]*0.7),:]\n",
    "en_fi__test = en_fi_.iloc[int(en_fi_.shape[0]*0.7):,:]\n",
    "\n",
    "X = en_fi__train.iloc[:,1:]\n",
    "Y = en_fi__train.iloc[:,0]\n",
    "X_test = en_fi__test.iloc[:,1:]\n",
    "Y_test = en_fi__test.iloc[:,0] \n",
    "\n",
    "model_en_fi_ = LinearRegression()\n",
    "model_en_fi_.fit(X,Y)\n",
    "\n",
    "final_model_en_fi = LinearRegression()\n",
    "final_model_en_fi.fit(X_full, Y_full)\n",
    "    \n",
    "result = pd.DataFrame(Y_test)\n",
    "result[\"regression_values\"] = model_en_fi_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "enclosed-aging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z-score</th>\n",
       "      <th>regression_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_values</th>\n",
       "      <td>0.474168</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    z-score  regression_values\n",
       "z-score            1.000000           0.474168\n",
       "regression_values  0.474168           1.000000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-assignment",
   "metadata": {},
   "source": [
    "## THE OVERALL BEST CORRELATIONS PER LANGUAGE PAIR "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-characteristic",
   "metadata": {},
   "source": [
    "##### RU EN\n",
    "* Regression with all 12 metrics included (0.368)\n",
    "\n",
    "##### DE EN\n",
    "* ROUGE L Fmeasure Pearson (0.328)\n",
    "\n",
    "##### CS EN\n",
    "* Regression with all 12 metrics included (0.483)\n",
    "\n",
    "##### ZH EN\n",
    "* Regression with all 12 metrics included (0.360)\n",
    "\n",
    "##### EN ZH\n",
    "* BLEU Corpus Pearson (0.424)\n",
    "\n",
    "##### EN FI\n",
    "* ROUGE 1 Precision Pearson (0.549)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-hughes",
   "metadata": {},
   "source": [
    "# Final Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "collectible-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "#importing the data\n",
    "\n",
    "path_corpus_test = \"/Users/franz/Downloads/testset/\"\n",
    "\n",
    "ru_en_test = pd.read_csv(path_corpus_test + \"ru-en/scores.csv\")\n",
    "de_en_test = pd.read_csv(path_corpus_test + \"de-en/scores.csv\")\n",
    "cs_en_test = pd.read_csv(path_corpus_test + \"cs-en/scores.csv\")\n",
    "zh_en_test = pd.read_csv(path_corpus_test + \"zh-en/scores.csv\")\n",
    "en_zh_test = pd.read_csv(path_corpus_test + \"en-zh/scores.csv\")\n",
    "en_fi_test = pd.read_csv(path_corpus_test + \"en-fi/scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "seeing-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the nan\n",
    "ru_en_test.iloc[9191,1] = \"This is a dummy text, as the nan has to be filled!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cheap-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(element):\n",
    "    # detect the language pair contained in the dataframe\n",
    "    pair = detect(element.iloc[0,0]) + \"_\" + detect(element.iloc[0,1])\n",
    "    \n",
    "    predicted_scores = []\n",
    "    \n",
    "    #check if pair in list, if so, all 12 metrics need to be computed to feed to the respective model\n",
    "    if pair in [\"ru_en\", \"cs_en\", \"zh-cn_en\"]:\n",
    "        \n",
    "        all_12_df = pd.DataFrame()\n",
    "        \n",
    "        bleu_star_scores = []\n",
    "        bleu_sentence_scores = []\n",
    "        bleu_corpus_scores = []\n",
    "        r_1_p = []\n",
    "        r_1_r = []\n",
    "        r_1_f = []\n",
    "        r_2_p = []\n",
    "        r_2_r = []\n",
    "        r_2_f = []\n",
    "        r_l_p = []\n",
    "        r_l_r = []\n",
    "        r_l_f = []\n",
    "\n",
    "        \n",
    "        for i in range(element.shape[0]):\n",
    "            #calculating the bleu star scores for the translations in comparison to their respective reference\n",
    "            reference = element.loc[i,\"reference\"]\n",
    "            translation = element.loc[i,\"translation\"]\n",
    "            bleu_star_scores.append(BLEU_star_compact(reference, translation))\n",
    "            \n",
    "            #calculating the bleu sentence scores for the translations in comparison to their respective reference\n",
    "            reference = [element.loc[i,\"reference\"].split()]\n",
    "            translation = element.loc[i,\"translation\"].split()\n",
    "            bleu_sentence_scores.append(sentence_bleu(reference, translation,weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "            \n",
    "            #calculating the bleu corpus scores for the translations in comparison to their respective reference\n",
    "            reference = [element.loc[i,\"reference\"].split()]\n",
    "            translation = element.loc[i,\"translation\"].split()\n",
    "            while len(reference) < len(translation):\n",
    "                reference.append(\" \")\n",
    "            while len(reference) > len(translation):\n",
    "                translation.append(\" \")\n",
    "            bleu_corpus_scores.append(corpus_bleu(reference, translation))\n",
    "        \n",
    "            #calculating all the ROUGE scores for the translations in comparison to their respective reference\n",
    "            scorer = rouge_scorer.RougeScorer(['rougeL', 'rouge1', 'rouge2'], use_stemmer=True)\n",
    "            scores = scorer.score(element.loc[i,\"reference\"], element.loc[i,\"translation\"])\n",
    "            \n",
    "            r_1_p.append(scores[\"rouge1\"].precision)\n",
    "            r_1_r.append(scores[\"rouge1\"].recall)\n",
    "            r_1_f.append(scores[\"rouge1\"].fmeasure)\n",
    "            \n",
    "            r_2_p.append(scores[\"rouge2\"].precision)\n",
    "            r_2_r.append(scores[\"rouge2\"].recall)\n",
    "            r_2_f.append(scores[\"rouge2\"].fmeasure)\n",
    "            \n",
    "            r_l_p.append(scores[\"rougeL\"].precision)\n",
    "            r_l_r.append(scores[\"rougeL\"].recall)\n",
    "            r_l_f.append(scores[\"rougeL\"].fmeasure)\n",
    "            \n",
    "        all_12_df[\"BLEU\"] = bleu_star_scores\n",
    "        all_12_df[\"BLEU_s\"] = bleu_sentence_scores\n",
    "        all_12_df[\"BLEU_c\"] = bleu_corpus_scores\n",
    "        all_12_df[\"ROUGE1_precision\"] = r_1_p\n",
    "        all_12_df[\"ROUGE1_recall\"] = r_1_r\n",
    "        all_12_df[\"ROUGE1_fmeasure\"] = r_1_f\n",
    "        all_12_df[\"ROUGE2_precision\"] = r_2_p\n",
    "        all_12_df[\"ROUGE2_recall\"] = r_2_r\n",
    "        all_12_df[\"ROUGE2_fmeasure\"] = r_2_f\n",
    "        all_12_df[\"ROUGEL_precision\"] = r_l_p\n",
    "        all_12_df[\"ROUGEL_recall\"] = r_l_r\n",
    "        all_12_df[\"ROUGEL_fmeasure\"] = r_l_f\n",
    "            \n",
    "        if pair == \"ru_en\":\n",
    "            return final_model_ru_en.predict(all_12_df)\n",
    "        elif pair == \"cs_en\":\n",
    "            return final_model_cs_en.predict(all_12_df)\n",
    "        elif pair == \"zh-cn_en\":\n",
    "            return final_model_zh_en.predict(all_12_df)\n",
    "                \n",
    "    elif pair in [\"de_en\", \"en_fi\"]:\n",
    "        for i in range(element.shape[0]):\n",
    "            scorer = rouge_scorer.RougeScorer(['rougeL', 'rouge1', 'rouge2'], use_stemmer=True)\n",
    "            scores = scorer.score(element.loc[i,\"reference\"], element.loc[i,\"translation\"])\n",
    "            if pair == \"de_en\":\n",
    "                predicted_scores.append(scores[\"rougeL\"].fmeasure)\n",
    "            elif pair == \"en_fi\":\n",
    "                predicted_scores.append(scores[\"rouge1\"].precision)\n",
    "                \n",
    "    elif pair == \"en_zh-cn\":\n",
    "        for i in range(element.shape[0]):\n",
    "            reference = [element.loc[i,\"reference\"].split()]\n",
    "            translation = element.loc[i,\"translation\"].split()\n",
    "            while len(reference) < len(translation):\n",
    "                reference.append(\" \")\n",
    "            while len(reference) > len(translation):\n",
    "                translation.append(\" \")\n",
    "            predicted_scores.append(corpus_bleu(reference, translation))\n",
    "        \n",
    "    return predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fitting-pennsylvania",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "ru_en_test[\"scores\"] = metric(ru_en_test)\n",
    "de_en_test[\"scores\"] = metric(de_en_test)\n",
    "cs_en_test[\"scores\"] = metric(cs_en_test)\n",
    "zh_en_test[\"scores\"] = metric(zh_en_test)\n",
    "en_zh_test[\"scores\"] = metric(en_zh_test)\n",
    "en_fi_test[\"scores\"] = metric(en_fi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "pretty-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_en_test.to_csv(path_corpus_test + \"ru-en/scores_added.csv\")\n",
    "de_en_test.to_csv(path_corpus_test + \"de-en/scores_added.csv\")\n",
    "cs_en_test.to_csv(path_corpus_test + \"cs-en/scores_added.csv\")\n",
    "zh_en_test.to_csv(path_corpus_test + \"zh-en/scores_added.csv\")\n",
    "en_zh_test.to_csv(path_corpus_test + \"en-zh/scores_added.csv\")\n",
    "en_fi_test.to_csv(path_corpus_test + \"en-fi/scores_added.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-matthew",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-newark",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-indonesia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-contractor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-trick",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-navigator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-making",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-emerald",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-mattress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-prototype",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-indication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-television",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-vermont",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-playback",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-first",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-nashville",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
