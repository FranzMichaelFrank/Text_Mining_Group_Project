{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aboriginal-contamination",
   "metadata": {},
   "source": [
    "# TM Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-importance",
   "metadata": {},
   "source": [
    "## Toughts\n",
    "* Should we apply the different metrics for each language pair respectively according to its best correlation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-thomas",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "final-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coated-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "\n",
    "path_corpus = \"/Users/franz/Desktop/TM Project/corpus/\"\n",
    "\n",
    "ru_en = pd.read_csv(path_corpus + \"ru-en/scores.csv\")\n",
    "de_en = pd.read_csv(path_corpus + \"de-en/scores.csv\")\n",
    "cs_en = pd.read_csv(path_corpus + \"cs-en/scores.csv\")\n",
    "zh_en = pd.read_csv(path_corpus + \"zh-en/scores.csv\")\n",
    "en_zh = pd.read_csv(path_corpus + \"en-zh/scores.csv\")\n",
    "en_fi = pd.read_csv(path_corpus + \"en-fi/scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opponent-updating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr Zeitlupentempo maßen sie, als sie vor Spit...</td>\n",
       "      <td>Her timeless pace measures them when they equi...</td>\n",
       "      <td>Their slow speed was measured by researchers o...</td>\n",
       "      <td>-0.345024</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Er sagte, dass die Bereiche ruhige Treffpunkte...</td>\n",
       "      <td>He said the areas offer quiet meeting points b...</td>\n",
       "      <td>He said the spaces provided calm meeting point...</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>97.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Für die Geschäftsleute an der B 27 ist es nur ...</td>\n",
       "      <td>For businessmen at the B 27, it's only a small...</td>\n",
       "      <td>This is only a small consolation for businesse...</td>\n",
       "      <td>0.700503</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diese Fähigkeit sei möglicherweise angeboren o...</td>\n",
       "      <td>This ability may be born or developed with gen...</td>\n",
       "      <td>This ability may be innate, or may develop as ...</td>\n",
       "      <td>-1.256572</td>\n",
       "      <td>51.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weil sie Wassertemperaturen um die sechs Grad ...</td>\n",
       "      <td>Because they prefer water temperatures around ...</td>\n",
       "      <td>They generally only come to the surface in win...</td>\n",
       "      <td>0.293909</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Ihr Zeitlupentempo maßen sie, als sie vor Spit...   \n",
       "1  Er sagte, dass die Bereiche ruhige Treffpunkte...   \n",
       "2  Für die Geschäftsleute an der B 27 ist es nur ...   \n",
       "3  Diese Fähigkeit sei möglicherweise angeboren o...   \n",
       "4  Weil sie Wassertemperaturen um die sechs Grad ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Her timeless pace measures them when they equi...   \n",
       "1  He said the areas offer quiet meeting points b...   \n",
       "2  For businessmen at the B 27, it's only a small...   \n",
       "3  This ability may be born or developed with gen...   \n",
       "4  Because they prefer water temperatures around ...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Their slow speed was measured by researchers o... -0.345024       76.0   \n",
       "1  He said the spaces provided calm meeting point...  0.903800       97.5   \n",
       "2  This is only a small consolation for businesse...  0.700503       94.0   \n",
       "3  This ability may be innate, or may develop as ... -1.256572       51.5   \n",
       "4  They generally only come to the surface in win...  0.293909       87.0   \n",
       "\n",
       "   annotators  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           2  \n",
       "4           2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-fitness",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "christian-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = [\"Russian into English\", \"German into English\", \"Czech into English\", \"Chinese into English\", \"English into Chinese\", \"English into Finish\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smoking-stroke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>avg z-score</th>\n",
       "      <th>avg avg-score</th>\n",
       "      <th>avg annotators</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Russian into English</th>\n",
       "      <td>17980.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>74.50</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German into English</th>\n",
       "      <td>21704.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.85</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Czech into English</th>\n",
       "      <td>11585.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>69.24</td>\n",
       "      <td>1.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinese into English</th>\n",
       "      <td>26419.0</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>66.06</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Chinese</th>\n",
       "      <td>10221.0</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>65.98</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Finish</th>\n",
       "      <td>6748.0</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>45.12</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         rows  avg z-score  avg avg-score  avg annotators\n",
       "description                                                              \n",
       "Russian into English  17980.0         0.01          74.50            1.30\n",
       "German into English   21704.0         0.00          71.85            1.50\n",
       "Czech into English    11585.0        -0.03          69.24            1.89\n",
       "Chinese into English  26419.0        -0.05          66.06            1.42\n",
       "English into Chinese  10221.0        -0.06          65.98            1.58\n",
       "English into Finish    6748.0        -0.14          45.12            1.23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "zscores = []\n",
    "avgscores = []\n",
    "annots = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    rows.append(element.shape[0])\n",
    "    zscores.append(np.round(element[\"z-score\"].mean(),2))\n",
    "    avgscores.append(np.round(element[\"avg-score\"].mean(), 2))\n",
    "    annots.append(np.round(element[\"annotators\"].mean(),2))\n",
    "    i += 1                   \n",
    "    \n",
    "exploration_df = pd.DataFrame([rows, zscores, avgscores, annots]).T.rename(columns={0:\"rows\", 1:\"avg z-score\", 2:\"avg avg-score\", 3:\"avg annotators\"})\n",
    "exploration_df[\"description\"] = descriptions\n",
    "exploration_df = exploration_df.set_index(\"description\")\n",
    "exploration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "agricultural-selection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>avg z-score</th>\n",
       "      <th>avg avg-score</th>\n",
       "      <th>avg annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rows</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.597505</td>\n",
       "      <td>0.579839</td>\n",
       "      <td>-0.105454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg z-score</th>\n",
       "      <td>0.597505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975645</td>\n",
       "      <td>0.310459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg avg-score</th>\n",
       "      <td>0.579839</td>\n",
       "      <td>0.975645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.417110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg annotators</th>\n",
       "      <td>-0.105454</td>\n",
       "      <td>0.310459</td>\n",
       "      <td>0.417110</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    rows  avg z-score  avg avg-score  avg annotators\n",
       "rows            1.000000     0.597505       0.579839       -0.105454\n",
       "avg z-score     0.597505     1.000000       0.975645        0.310459\n",
       "avg avg-score   0.579839     0.975645       1.000000        0.417110\n",
       "avg annotators -0.105454     0.310459       0.417110        1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploration_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-president",
   "metadata": {},
   "source": [
    "As there are only 6 different types of translations, these correlations might be not very meaningful!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-intellectual",
   "metadata": {},
   "source": [
    "# Lexical metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-contract",
   "metadata": {},
   "source": [
    "## BLEU Score - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-afternoon",
   "metadata": {},
   "source": [
    "##### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-greenhouse",
   "metadata": {},
   "source": [
    "The BLEU Score might require multiple reference sentences, hence it might not be suitable for our problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-spoke",
   "metadata": {},
   "source": [
    "Inspiration taken from \n",
    "* https://towardsdatascience.com/nlp-metrics-made-simple-the-bleu-score-b06b14fbdbc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "compact-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# a more \"pythonic\" way to compute BLUE_star \n",
    "\n",
    "def BLEU_star_compact(refs, candidate):\n",
    "    refs = [refs.split()]\n",
    "    candidate = candidate.split()\n",
    "\n",
    "    return sum([min(count, max([ref[word] for ref in [Counter(ref) for ref in refs]])) for word, count in Counter(candidate).items()])/len(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "joint-rolling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCorrelation between z-score and BLEU score\n",
      "\n",
      "\u001b[1m Russian into English: \u001b[0mPearson: 0.3198 | Kendall: 0.2168\n",
      "\u001b[1m German into English: \u001b[0mPearson: 0.2907 | Kendall: 0.2039\n",
      "\u001b[1m Czech into English: \u001b[0mPearson: 0.4245 | Kendall: 0.2871\n",
      "\u001b[1m Chinese into English: \u001b[0mPearson: 0.3385 | Kendall: 0.2264\n",
      "\u001b[1m English into Chinese: \u001b[0mPearson: 0.0308 | Kendall: 0.0116\n",
      "\u001b[1m English into Finish: \u001b[0mPearson: 0.5084 | Kendall: 0.3383\n",
      "\n",
      "\u001b[1mOverall:\u001b[0m Average Pearson: 0.3188 | Average Kendall: 0.214\n"
     ]
    }
   ],
   "source": [
    "overall_results = {}\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    bleu_scores = []\n",
    "\n",
    "    #calculating the bleu scores for the translations in comparison to their respective reference\n",
    "    for i in range(6748): #element.shape[0]\n",
    "        reference = element.loc[i,\"reference\"]\n",
    "        translation = element.loc[i,\"translation\"]\n",
    "        bleu_scores.append(BLEU_star_compact(reference, translation))\n",
    "\n",
    "    #add the bleu scores to the dataframe\n",
    "    development_df = element.iloc[:6748,:].copy() #element.shape[0]\n",
    "    development_df[\"BLEU\"] = bleu_scores\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "\n",
    "\n",
    "print(\"\\033[1mCorrelation between z-score and BLEU score\\n\")\n",
    "i = 0\n",
    "for element in correlations_p:\n",
    "    print(\"\\033[1m\", descriptions[i] + \":\",  \"\\033[0mPearson:\", np.round(element,4), \"| Kendall:\", np.round(correlations_k[i],4))\n",
    "    i += 1\n",
    "\n",
    "print(\"\\n\\033[1mOverall:\\033[0m Average Pearson:\", np.round(sum(correlations_p)/len(correlations_p),4),\n",
    "         \"| Average Kendall:\", np.round(sum(correlations_k)/len(correlations_k),4))\n",
    "\n",
    "overall_results[\"BLEU Star Pearson\"] = correlations_p\n",
    "overall_results[\"BLEU Star Kendall\"] = correlations_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-explanation",
   "metadata": {},
   "source": [
    "## BLEU Score - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-desperate",
   "metadata": {},
   "source": [
    "### 1st Try (sentence_bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-trademark",
   "metadata": {},
   "source": [
    "Inspiration taken from \n",
    "* https://www.journaldev.com/46659/bleu-score-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "million-yeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCorrelation between z-score and BLEU score\n",
      "\n",
      "\u001b[1m Russian into English: \u001b[0mPearson: 0.248 | Kendall: 0.1799\n",
      "\u001b[1m German into English: \u001b[0mPearson: 0.2415 | Kendall: 0.1698\n",
      "\u001b[1m Czech into English: \u001b[0mPearson: 0.2831 | Kendall: 0.2227\n",
      "\u001b[1m Chinese into English: \u001b[0mPearson: 0.2482 | Kendall: 0.1783\n",
      "\u001b[1m English into Chinese: \u001b[0mPearson: 0.0183 | Kendall: 0.0116\n",
      "\u001b[1m English into Finish: \u001b[0mPearson: 0.2623 | Kendall: 0.2896\n",
      "\n",
      "\u001b[1mOverall:\u001b[0m Average Pearson: 0.2169 | Average Kendall: 0.1753\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    bleu_scores = []\n",
    "\n",
    "    #calculating the bleu scores for the translations in comparison to their respective reference\n",
    "    for i in range(6748): #element.shape[0]\n",
    "        reference = [element.loc[i,\"reference\"].split()]\n",
    "        translation = element.loc[i,\"translation\"].split()\n",
    "        bleu_scores.append(sentence_bleu(reference, translation,weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n",
    "    #add the bleu scores to the dataframe\n",
    "    development_df = element.iloc[:6748,:].copy() #element.shape[0]\n",
    "    development_df[\"BLEU\"] = bleu_scores\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "\n",
    "\n",
    "print(\"\\033[1mCorrelation between z-score and BLEU score\\n\")\n",
    "i = 0\n",
    "for element in correlations_p:\n",
    "    print(\"\\033[1m\", descriptions[i] + \":\",  \"\\033[0mPearson:\", np.round(element,4), \"| Kendall:\", np.round(correlations_k[i],4))\n",
    "    i += 1\n",
    "\n",
    "print(\"\\n\\033[1mOverall:\\033[0m Average Pearson:\", np.round(sum(correlations_p)/len(correlations_p),4),\n",
    "         \"| Average Kendall:\", np.round(sum(correlations_k)/len(correlations_k),4))\n",
    "\n",
    "overall_results[\"BLEU Sentence Pearson\"] = correlations_p\n",
    "overall_results[\"BLEU Sentence Kendall\"] = correlations_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-amber",
   "metadata": {},
   "source": [
    "### 2nd Try (corpus_bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-budget",
   "metadata": {},
   "source": [
    "Inspiration taken from:\n",
    "* https://stackoverflow.com/questions/62337356/bleu-error-n-gram-overlaps-of-lower-order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adolescent-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCorrelation between z-score and BLEU score\n",
      "\n",
      "\u001b[1m Russian into English: \u001b[0mPearson 0.0346 | Kendall: 0.0563\n",
      "\u001b[1m German into English: \u001b[0mPearson 0.0355 | Kendall: 0.0536\n",
      "\u001b[1m Czech into English: \u001b[0mPearson 0.1055 | Kendall: 0.1019\n",
      "\u001b[1m Chinese into English: \u001b[0mPearson 0.0587 | Kendall: 0.055\n",
      "\u001b[1m English into Chinese: \u001b[0mPearson 0.4144 | Kendall: 0.2907\n",
      "\u001b[1m English into Finish: \u001b[0mPearson 0.2355 | Kendall: 0.1723\n",
      "\n",
      "\u001b[1mOverall:\u001b[0m Average Pearson: 0.1474 | Average Kendall: 0.1216\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    bleu_scores = []\n",
    "\n",
    "    #calculating the bleu scores for the translations in comparison to their respective reference\n",
    "    for i in range(6748): #element.shape[0]\n",
    "        reference = [element.loc[i,\"reference\"].split()]\n",
    "        translation = element.loc[i,\"translation\"].split()\n",
    "        while len(reference) < len(translation):\n",
    "            reference.append(\" \")\n",
    "        while len(reference) > len(translation):\n",
    "            translation.append(\" \")\n",
    "        bleu_scores.append(corpus_bleu(reference, translation))\n",
    "\n",
    "    #add the bleu scores to the dataframe\n",
    "    development_df = element.iloc[:6748,:].copy() #element.shape[0]\n",
    "    development_df[\"BLEU\"] = bleu_scores\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "\n",
    "\n",
    "print(\"\\033[1mCorrelation between z-score and BLEU score\\n\")\n",
    "i = 0\n",
    "for element in correlations_p:\n",
    "    print(\"\\033[1m\", descriptions[i] + \":\",  \"\\033[0mPearson\", np.round(element,4), \"| Kendall:\", np.round(correlations_k[i],4))\n",
    "    i += 1\n",
    "\n",
    "print(\"\\n\\033[1mOverall:\\033[0m Average Pearson:\", np.round(sum(correlations_p)/len(correlations_p),4),\n",
    "         \"| Average Kendall:\", np.round(sum(correlations_k)/len(correlations_k),4))\n",
    "\n",
    "overall_results[\"BLEU Corpus Pearson\"] = correlations_p\n",
    "overall_results[\"BLEU Corpus Kendall\"] = correlations_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-divide",
   "metadata": {},
   "source": [
    "## ROUGE Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-cooperation",
   "metadata": {},
   "source": [
    "Inspiration taken from:\n",
    "* https://pypi.org/project/rouge-score/\n",
    "* https://towardsdatascience.com/the-ultimate-performance-metric-in-nlp-111df6c64460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "stock-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --target=/Users/franz/opt/anaconda3/envs/Data_visualization/lib/python3.8/site-packages/ rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-donor",
   "metadata": {},
   "source": [
    "### ROUGE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "everyday-oxford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPearson Correlation between z-score and ROUGE measures (ROUGE 1) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.333682</td>\n",
       "      <td>0.308229</td>\n",
       "      <td>0.450566</td>\n",
       "      <td>0.360388</td>\n",
       "      <td>0.066999</td>\n",
       "      <td>0.549302</td>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.287828</td>\n",
       "      <td>0.299770</td>\n",
       "      <td>0.376656</td>\n",
       "      <td>0.279403</td>\n",
       "      <td>0.065452</td>\n",
       "      <td>0.513220</td>\n",
       "      <td>0.303721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.332984</td>\n",
       "      <td>0.326371</td>\n",
       "      <td>0.440464</td>\n",
       "      <td>0.348995</td>\n",
       "      <td>0.071994</td>\n",
       "      <td>0.544540</td>\n",
       "      <td>0.344225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.333682             0.308229   \n",
       "ROUGE recall                 0.287828             0.299770   \n",
       "ROUGE fmeasure               0.332984             0.326371   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.450566              0.360388   \n",
       "ROUGE recall               0.376656              0.279403   \n",
       "ROUGE fmeasure             0.440464              0.348995   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.066999             0.549302  0.344861  \n",
       "ROUGE recall                 0.065452             0.513220  0.303721  \n",
       "ROUGE fmeasure               0.071994             0.544540  0.344225  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "results_p = pd.DataFrame()\n",
    "results_k = pd.DataFrame()\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "j = 0\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    fmeasures = []\n",
    "\n",
    "    #calculating the rouge scores for the translations in comparison to their respective reference\n",
    "    for i in range(6748): #element.shape[0]\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(element.loc[i,\"reference\"], element.loc[i,\"translation\"])\n",
    "        precisions.append(scores[\"rouge1\"].precision)\n",
    "        recalls.append(scores[\"rouge1\"].recall)\n",
    "        fmeasures.append(scores[\"rouge1\"].fmeasure)\n",
    "\n",
    "    #add the rouge scores to the dataframe\n",
    "    development_df = element.iloc[:6748,:].copy() #element.shape[0]\n",
    "    development_df[\"ROUGE precision\"] = precisions\n",
    "    development_df[\"ROUGE recall\"] = recalls\n",
    "    development_df[\"ROUGE fmeasure\"] = fmeasures\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "    col_name = descriptions[j]\n",
    "    j += 1\n",
    "    results_p[col_name] = pd.Series(development_df.corr(method=\"pearson\").iloc[0,3:])\n",
    "    results_k[col_name] = pd.Series(development_df.corr(method=\"kendall\").iloc[0,3:])\n",
    "\n",
    "\n",
    "print(\"\\033[1mPearson Correlation between z-score and ROUGE measures (ROUGE 1) \\n\")\n",
    "\n",
    "\n",
    "overall_results[\"ROUGE 1 Precision Pearson\"] = results_p.iloc[0,:6].values.tolist()\n",
    "overall_results[\"ROUGE 1 Recall Pearson\"] = results_p.iloc[1,:6].values.tolist()\n",
    "overall_results[\"ROUGE 1 Fmeasure Pearson\"] = results_p.iloc[2,:6].values.tolist()\n",
    "\n",
    "results_p[\"Average\"] = results_p.T.mean()\n",
    "results_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "shared-death",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mKendall Tau Correlation between z-score and ROUGE measures (ROUGE 1) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.221403</td>\n",
       "      <td>0.218162</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.240620</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.363198</td>\n",
       "      <td>0.231964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.192943</td>\n",
       "      <td>0.212362</td>\n",
       "      <td>0.249312</td>\n",
       "      <td>0.181416</td>\n",
       "      <td>0.043840</td>\n",
       "      <td>0.332239</td>\n",
       "      <td>0.202019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.223334</td>\n",
       "      <td>0.227899</td>\n",
       "      <td>0.295210</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>0.047778</td>\n",
       "      <td>0.354801</td>\n",
       "      <td>0.229696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.221403             0.218162   \n",
       "ROUGE recall                 0.192943             0.212362   \n",
       "ROUGE fmeasure               0.223334             0.227899   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.304000              0.240620   \n",
       "ROUGE recall               0.249312              0.181416   \n",
       "ROUGE fmeasure             0.295210              0.229154   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.044400             0.363198  0.231964  \n",
       "ROUGE recall                 0.043840             0.332239  0.202019  \n",
       "ROUGE fmeasure               0.047778             0.354801  0.229696  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\033[1mKendall Tau Correlation between z-score and ROUGE measures (ROUGE 1) \\n\")\n",
    "\n",
    "overall_results[\"ROUGE 1 Precision Kendall\"] = results_k.iloc[0,:6].values.tolist()\n",
    "overall_results[\"ROUGE 1 Recall Kendall\"] = results_k.iloc[1,:6].values.tolist()\n",
    "overall_results[\"ROUGE 1 Fmeasure Kendall\"] = results_k.iloc[2,:6].values.tolist()\n",
    "\n",
    "results_k[\"Average\"] = results_k.T.mean()\n",
    "results_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-times",
   "metadata": {},
   "source": [
    "### ROUGE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "figured-punch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPearson Correlation between z-score and ROUGE measures (ROUGE 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.317852</td>\n",
       "      <td>0.302509</td>\n",
       "      <td>0.403146</td>\n",
       "      <td>0.320802</td>\n",
       "      <td>0.080609</td>\n",
       "      <td>0.468350</td>\n",
       "      <td>0.315545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.298319</td>\n",
       "      <td>0.289925</td>\n",
       "      <td>0.369502</td>\n",
       "      <td>0.290357</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.444354</td>\n",
       "      <td>0.295909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.314050</td>\n",
       "      <td>0.302747</td>\n",
       "      <td>0.395101</td>\n",
       "      <td>0.313292</td>\n",
       "      <td>0.086130</td>\n",
       "      <td>0.461915</td>\n",
       "      <td>0.312206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.317852             0.302509   \n",
       "ROUGE recall                 0.298319             0.289925   \n",
       "ROUGE fmeasure               0.314050             0.302747   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.403146              0.320802   \n",
       "ROUGE recall               0.369502              0.290357   \n",
       "ROUGE fmeasure             0.395101              0.313292   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.080609             0.468350  0.315545  \n",
       "ROUGE recall                 0.083000             0.444354  0.295909  \n",
       "ROUGE fmeasure               0.086130             0.461915  0.312206  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "results_p = pd.DataFrame()\n",
    "results_k = pd.DataFrame()\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "j = 0\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    fmeasures = []\n",
    "\n",
    "    #calculating the rouge scores for the translations in comparison to their respective reference\n",
    "    for i in range(6748): #element.shape[0]\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(element.loc[i,\"reference\"], element.loc[i,\"translation\"])\n",
    "        precisions.append(scores[\"rouge2\"].precision)\n",
    "        recalls.append(scores[\"rouge2\"].recall)\n",
    "        fmeasures.append(scores[\"rouge2\"].fmeasure)\n",
    "\n",
    "    #add the rouge scores to the dataframe\n",
    "    development_df = element.iloc[:6748,:].copy() #element.shape[0]\n",
    "    development_df[\"ROUGE precision\"] = precisions\n",
    "    development_df[\"ROUGE recall\"] = recalls\n",
    "    development_df[\"ROUGE fmeasure\"] = fmeasures\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "    col_name = descriptions[j]\n",
    "    j += 1\n",
    "    results_p[col_name] = pd.Series(development_df.corr(method=\"pearson\").iloc[0,3:])\n",
    "    results_k[col_name] = pd.Series(development_df.corr(method=\"kendall\").iloc[0,3:])\n",
    "\n",
    "\n",
    "print(\"\\033[1mPearson Correlation between z-score and ROUGE measures (ROUGE 2) \\n\")\n",
    "\n",
    "overall_results[\"ROUGE 2 Precision Pearson\"] = results_p.iloc[0,:6].values.tolist()\n",
    "overall_results[\"ROUGE 2 Recall Pearson\"] = results_p.iloc[1,:6].values.tolist()\n",
    "overall_results[\"ROUGE 2 Fmeasure Pearson\"] = results_p.iloc[2,:6].values.tolist()\n",
    "\n",
    "results_p[\"Average\"] = results_p.T.mean()\n",
    "results_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "given-syndication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mKendall Tau Correlation between z-score and ROUGE measures (ROUGE 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.219654</td>\n",
       "      <td>0.211056</td>\n",
       "      <td>0.280131</td>\n",
       "      <td>0.214792</td>\n",
       "      <td>0.058583</td>\n",
       "      <td>0.320441</td>\n",
       "      <td>0.217443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.205574</td>\n",
       "      <td>0.203474</td>\n",
       "      <td>0.253486</td>\n",
       "      <td>0.191793</td>\n",
       "      <td>0.059493</td>\n",
       "      <td>0.304527</td>\n",
       "      <td>0.203058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.215878</td>\n",
       "      <td>0.210021</td>\n",
       "      <td>0.270441</td>\n",
       "      <td>0.206967</td>\n",
       "      <td>0.060129</td>\n",
       "      <td>0.314192</td>\n",
       "      <td>0.212938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.219654             0.211056   \n",
       "ROUGE recall                 0.205574             0.203474   \n",
       "ROUGE fmeasure               0.215878             0.210021   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.280131              0.214792   \n",
       "ROUGE recall               0.253486              0.191793   \n",
       "ROUGE fmeasure             0.270441              0.206967   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.058583             0.320441  0.217443  \n",
       "ROUGE recall                 0.059493             0.304527  0.203058  \n",
       "ROUGE fmeasure               0.060129             0.314192  0.212938  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\033[1mKendall Tau Correlation between z-score and ROUGE measures (ROUGE 2) \\n\")\n",
    "\n",
    "overall_results[\"ROUGE 2 Precision Kendall\"] = results_k.iloc[0,:6].values.tolist()\n",
    "overall_results[\"ROUGE 2 Recall Kendall\"] = results_k.iloc[1,:6].values.tolist()\n",
    "overall_results[\"ROUGE 2 Fmeasure Kendall\"] = results_k.iloc[2,:6].values.tolist()\n",
    "\n",
    "results_k[\"Average\"] = results_k.T.mean()\n",
    "results_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-valley",
   "metadata": {},
   "source": [
    "### ROUGE L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "thermal-virgin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPearson Correlation between z-score and ROUGE measures (ROUGE L) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.341043</td>\n",
       "      <td>0.317401</td>\n",
       "      <td>0.467481</td>\n",
       "      <td>0.354257</td>\n",
       "      <td>0.068515</td>\n",
       "      <td>0.540008</td>\n",
       "      <td>0.348118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.304441</td>\n",
       "      <td>0.309437</td>\n",
       "      <td>0.402230</td>\n",
       "      <td>0.291957</td>\n",
       "      <td>0.068080</td>\n",
       "      <td>0.505371</td>\n",
       "      <td>0.313586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.340184</td>\n",
       "      <td>0.331321</td>\n",
       "      <td>0.455608</td>\n",
       "      <td>0.346621</td>\n",
       "      <td>0.074154</td>\n",
       "      <td>0.535137</td>\n",
       "      <td>0.347171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.341043             0.317401   \n",
       "ROUGE recall                 0.304441             0.309437   \n",
       "ROUGE fmeasure               0.340184             0.331321   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.467481              0.354257   \n",
       "ROUGE recall               0.402230              0.291957   \n",
       "ROUGE fmeasure             0.455608              0.346621   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.068515             0.540008  0.348118  \n",
       "ROUGE recall                 0.068080             0.505371  0.313586  \n",
       "ROUGE fmeasure               0.074154             0.535137  0.347171  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "results_p = pd.DataFrame()\n",
    "results_k = pd.DataFrame()\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "j = 0\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    fmeasures = []\n",
    "\n",
    "    #calculating the rouge scores for the translations in comparison to their respective reference\n",
    "    for i in range(6748): #element.shape[0]\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(element.loc[i,\"reference\"], element.loc[i,\"translation\"])\n",
    "        precisions.append(scores[\"rougeL\"].precision)\n",
    "        recalls.append(scores[\"rougeL\"].recall)\n",
    "        fmeasures.append(scores[\"rougeL\"].fmeasure)\n",
    "\n",
    "    #add the rouge scores to the dataframe\n",
    "    development_df = element.iloc[:6748,:].copy() #element.shape[0]\n",
    "    development_df[\"ROUGE precision\"] = precisions\n",
    "    development_df[\"ROUGE recall\"] = recalls\n",
    "    development_df[\"ROUGE fmeasure\"] = fmeasures\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "    col_name = descriptions[j]\n",
    "    j += 1\n",
    "    results_p[col_name] = pd.Series(development_df.corr(method=\"pearson\").iloc[0,3:])\n",
    "    results_k[col_name] = pd.Series(development_df.corr(method=\"kendall\").iloc[0,3:])\n",
    "\n",
    "\n",
    "print(\"\\033[1mPearson Correlation between z-score and ROUGE measures (ROUGE L) \\n\")\n",
    "\n",
    "overall_results[\"ROUGE L Precision Pearson\"] = results_p.iloc[0,:6].values.tolist()\n",
    "overall_results[\"ROUGE L Recall Pearson\"] = results_p.iloc[1,:6].values.tolist()\n",
    "overall_results[\"ROUGE L Fmeasure Pearson\"] = results_p.iloc[2,:6].values.tolist()\n",
    "\n",
    "results_p[\"Average\"] = results_p.T.mean()\n",
    "results_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "increased-millennium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mKendall Tau Correlation between z-score and ROUGE measures (ROUGE L) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.231716</td>\n",
       "      <td>0.226267</td>\n",
       "      <td>0.316472</td>\n",
       "      <td>0.239964</td>\n",
       "      <td>0.044429</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.235758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.209684</td>\n",
       "      <td>0.220059</td>\n",
       "      <td>0.269153</td>\n",
       "      <td>0.196207</td>\n",
       "      <td>0.044658</td>\n",
       "      <td>0.326671</td>\n",
       "      <td>0.211072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.232707</td>\n",
       "      <td>0.232192</td>\n",
       "      <td>0.305452</td>\n",
       "      <td>0.230285</td>\n",
       "      <td>0.048037</td>\n",
       "      <td>0.347729</td>\n",
       "      <td>0.232734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.231716             0.226267   \n",
       "ROUGE recall                 0.209684             0.220059   \n",
       "ROUGE fmeasure               0.232707             0.232192   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.316472              0.239964   \n",
       "ROUGE recall               0.269153              0.196207   \n",
       "ROUGE fmeasure             0.305452              0.230285   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.044429             0.355700  0.235758  \n",
       "ROUGE recall                 0.044658             0.326671  0.211072  \n",
       "ROUGE fmeasure               0.048037             0.347729  0.232734  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\033[1mKendall Tau Correlation between z-score and ROUGE measures (ROUGE L) \\n\")\n",
    "\n",
    "overall_results[\"ROUGE L Precision Kendall\"] = results_k.iloc[0,:6].values.tolist()\n",
    "overall_results[\"ROUGE L Recall Kendall\"] = results_k.iloc[1,:6].values.tolist()\n",
    "overall_results[\"ROUGE L Fmeasure Kendall\"] = results_k.iloc[2,:6].values.tolist()\n",
    "\n",
    "results_k[\"Average\"] = results_k.T.mean()\n",
    "results_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-pension",
   "metadata": {},
   "source": [
    "## RESULTS TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "neither-portland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLEU Star Pearson</th>\n",
       "      <td>0.319829</td>\n",
       "      <td>0.290713</td>\n",
       "      <td>0.424481</td>\n",
       "      <td>0.338450</td>\n",
       "      <td>0.030846</td>\n",
       "      <td>0.508383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU Sentence Pearson</th>\n",
       "      <td>0.247967</td>\n",
       "      <td>0.241474</td>\n",
       "      <td>0.283068</td>\n",
       "      <td>0.248230</td>\n",
       "      <td>0.018344</td>\n",
       "      <td>0.262296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU Corpus Pearson</th>\n",
       "      <td>0.034586</td>\n",
       "      <td>0.035531</td>\n",
       "      <td>0.105539</td>\n",
       "      <td>0.058663</td>\n",
       "      <td>0.414448</td>\n",
       "      <td>0.235517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Precision Pearson</th>\n",
       "      <td>0.333682</td>\n",
       "      <td>0.308229</td>\n",
       "      <td>0.450566</td>\n",
       "      <td>0.360388</td>\n",
       "      <td>0.066999</td>\n",
       "      <td>0.549302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Recall Pearson</th>\n",
       "      <td>0.287828</td>\n",
       "      <td>0.299770</td>\n",
       "      <td>0.376656</td>\n",
       "      <td>0.279403</td>\n",
       "      <td>0.065452</td>\n",
       "      <td>0.513220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Fmeasure Pearson</th>\n",
       "      <td>0.332984</td>\n",
       "      <td>0.326371</td>\n",
       "      <td>0.440464</td>\n",
       "      <td>0.348995</td>\n",
       "      <td>0.071994</td>\n",
       "      <td>0.544540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Precision Pearson</th>\n",
       "      <td>0.317852</td>\n",
       "      <td>0.302509</td>\n",
       "      <td>0.403146</td>\n",
       "      <td>0.320802</td>\n",
       "      <td>0.080609</td>\n",
       "      <td>0.468350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Recall Pearson</th>\n",
       "      <td>0.298319</td>\n",
       "      <td>0.289925</td>\n",
       "      <td>0.369502</td>\n",
       "      <td>0.290357</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.444354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Fmeasure Pearson</th>\n",
       "      <td>0.314050</td>\n",
       "      <td>0.302747</td>\n",
       "      <td>0.395101</td>\n",
       "      <td>0.313292</td>\n",
       "      <td>0.086130</td>\n",
       "      <td>0.461915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Precision Pearson</th>\n",
       "      <td>0.341043</td>\n",
       "      <td>0.317401</td>\n",
       "      <td>0.467481</td>\n",
       "      <td>0.354257</td>\n",
       "      <td>0.068515</td>\n",
       "      <td>0.540008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Recall Pearson</th>\n",
       "      <td>0.304441</td>\n",
       "      <td>0.309437</td>\n",
       "      <td>0.402230</td>\n",
       "      <td>0.291957</td>\n",
       "      <td>0.068080</td>\n",
       "      <td>0.505371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Fmeasure Pearson</th>\n",
       "      <td>0.340184</td>\n",
       "      <td>0.331321</td>\n",
       "      <td>0.455608</td>\n",
       "      <td>0.346621</td>\n",
       "      <td>0.074154</td>\n",
       "      <td>0.535137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Russian into English  German into English  \\\n",
       "BLEU Star Pearson                      0.319829             0.290713   \n",
       "BLEU Sentence Pearson                  0.247967             0.241474   \n",
       "BLEU Corpus Pearson                    0.034586             0.035531   \n",
       "ROUGE 1 Precision Pearson              0.333682             0.308229   \n",
       "ROUGE 1 Recall Pearson                 0.287828             0.299770   \n",
       "ROUGE 1 Fmeasure Pearson               0.332984             0.326371   \n",
       "ROUGE 2 Precision Pearson              0.317852             0.302509   \n",
       "ROUGE 2 Recall Pearson                 0.298319             0.289925   \n",
       "ROUGE 2 Fmeasure Pearson               0.314050             0.302747   \n",
       "ROUGE L Precision Pearson              0.341043             0.317401   \n",
       "ROUGE L Recall Pearson                 0.304441             0.309437   \n",
       "ROUGE L Fmeasure Pearson               0.340184             0.331321   \n",
       "\n",
       "                           Czech into English  Chinese into English  \\\n",
       "BLEU Star Pearson                    0.424481              0.338450   \n",
       "BLEU Sentence Pearson                0.283068              0.248230   \n",
       "BLEU Corpus Pearson                  0.105539              0.058663   \n",
       "ROUGE 1 Precision Pearson            0.450566              0.360388   \n",
       "ROUGE 1 Recall Pearson               0.376656              0.279403   \n",
       "ROUGE 1 Fmeasure Pearson             0.440464              0.348995   \n",
       "ROUGE 2 Precision Pearson            0.403146              0.320802   \n",
       "ROUGE 2 Recall Pearson               0.369502              0.290357   \n",
       "ROUGE 2 Fmeasure Pearson             0.395101              0.313292   \n",
       "ROUGE L Precision Pearson            0.467481              0.354257   \n",
       "ROUGE L Recall Pearson               0.402230              0.291957   \n",
       "ROUGE L Fmeasure Pearson             0.455608              0.346621   \n",
       "\n",
       "                           English into Chinese  English into Finish  \n",
       "BLEU Star Pearson                      0.030846             0.508383  \n",
       "BLEU Sentence Pearson                  0.018344             0.262296  \n",
       "BLEU Corpus Pearson                    0.414448             0.235517  \n",
       "ROUGE 1 Precision Pearson              0.066999             0.549302  \n",
       "ROUGE 1 Recall Pearson                 0.065452             0.513220  \n",
       "ROUGE 1 Fmeasure Pearson               0.071994             0.544540  \n",
       "ROUGE 2 Precision Pearson              0.080609             0.468350  \n",
       "ROUGE 2 Recall Pearson                 0.083000             0.444354  \n",
       "ROUGE 2 Fmeasure Pearson               0.086130             0.461915  \n",
       "ROUGE L Precision Pearson              0.068515             0.540008  \n",
       "ROUGE L Recall Pearson                 0.068080             0.505371  \n",
       "ROUGE L Fmeasure Pearson               0.074154             0.535137  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsons = []\n",
    "kendalls = []\n",
    "\n",
    "for element in list(overall_results.keys()):\n",
    "    if element.endswith(\"Pearson\"):\n",
    "        pearsons.append(element)\n",
    "    elif element.endswith(\"Kendall\"):\n",
    "        kendalls.append(element)\n",
    "        \n",
    "dict_pearson = { your_key: overall_results[your_key] for your_key in pearsons }\n",
    "dict_kendall = { your_key: overall_results[your_key] for your_key in kendalls }\n",
    "\n",
    "pearson_df = pd.DataFrame(list(dict_pearson.values()), index=list(dict_pearson.keys()), columns=descriptions)\n",
    "pearson_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "intellectual-evans",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric with highest correlation</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Russian into English</th>\n",
       "      <td>ROUGE L Precision Pearson</td>\n",
       "      <td>0.341043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German into English</th>\n",
       "      <td>ROUGE L Fmeasure Pearson</td>\n",
       "      <td>0.331321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Czech into English</th>\n",
       "      <td>ROUGE L Precision Pearson</td>\n",
       "      <td>0.467481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinese into English</th>\n",
       "      <td>ROUGE 1 Precision Pearson</td>\n",
       "      <td>0.360388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Chinese</th>\n",
       "      <td>BLEU Corpus Pearson</td>\n",
       "      <td>0.414448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Finish</th>\n",
       "      <td>ROUGE 1 Precision Pearson</td>\n",
       "      <td>0.549302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metric with highest correlation     Value\n",
       "Russian into English       ROUGE L Precision Pearson  0.341043\n",
       "German into English         ROUGE L Fmeasure Pearson  0.331321\n",
       "Czech into English         ROUGE L Precision Pearson  0.467481\n",
       "Chinese into English       ROUGE 1 Precision Pearson  0.360388\n",
       "English into Chinese             BLEU Corpus Pearson  0.414448\n",
       "English into Finish        ROUGE 1 Precision Pearson  0.549302"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_evaluation = pd.DataFrame(pearson_df.idxmax(), columns=[\"Metric with highest correlation\"])\n",
    "pearson_evaluation[\"Value\"] = pearson_df.max()\n",
    "pearson_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "tight-cylinder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BLEU Star Kendall</th>\n",
       "      <td>0.216759</td>\n",
       "      <td>0.203917</td>\n",
       "      <td>0.287051</td>\n",
       "      <td>0.226367</td>\n",
       "      <td>0.011641</td>\n",
       "      <td>0.338281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU Sentence Kendall</th>\n",
       "      <td>0.179918</td>\n",
       "      <td>0.169787</td>\n",
       "      <td>0.222721</td>\n",
       "      <td>0.178306</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.289645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLEU Corpus Kendall</th>\n",
       "      <td>0.056322</td>\n",
       "      <td>0.053605</td>\n",
       "      <td>0.101863</td>\n",
       "      <td>0.054996</td>\n",
       "      <td>0.290729</td>\n",
       "      <td>0.172336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Precision Kendall</th>\n",
       "      <td>0.221403</td>\n",
       "      <td>0.218162</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.240620</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.363198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Recall Kendall</th>\n",
       "      <td>0.192943</td>\n",
       "      <td>0.212362</td>\n",
       "      <td>0.249312</td>\n",
       "      <td>0.181416</td>\n",
       "      <td>0.043840</td>\n",
       "      <td>0.332239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 1 Fmeasure Kendall</th>\n",
       "      <td>0.223334</td>\n",
       "      <td>0.227899</td>\n",
       "      <td>0.295210</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>0.047778</td>\n",
       "      <td>0.354801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Precision Kendall</th>\n",
       "      <td>0.219654</td>\n",
       "      <td>0.211056</td>\n",
       "      <td>0.280131</td>\n",
       "      <td>0.214792</td>\n",
       "      <td>0.058583</td>\n",
       "      <td>0.320441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Recall Kendall</th>\n",
       "      <td>0.205574</td>\n",
       "      <td>0.203474</td>\n",
       "      <td>0.253486</td>\n",
       "      <td>0.191793</td>\n",
       "      <td>0.059493</td>\n",
       "      <td>0.304527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE 2 Fmeasure Kendall</th>\n",
       "      <td>0.215878</td>\n",
       "      <td>0.210021</td>\n",
       "      <td>0.270441</td>\n",
       "      <td>0.206967</td>\n",
       "      <td>0.060129</td>\n",
       "      <td>0.314192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Precision Kendall</th>\n",
       "      <td>0.231716</td>\n",
       "      <td>0.226267</td>\n",
       "      <td>0.316472</td>\n",
       "      <td>0.239964</td>\n",
       "      <td>0.044429</td>\n",
       "      <td>0.355700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Recall Kendall</th>\n",
       "      <td>0.209684</td>\n",
       "      <td>0.220059</td>\n",
       "      <td>0.269153</td>\n",
       "      <td>0.196207</td>\n",
       "      <td>0.044658</td>\n",
       "      <td>0.326671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE L Fmeasure Kendall</th>\n",
       "      <td>0.232707</td>\n",
       "      <td>0.232192</td>\n",
       "      <td>0.305452</td>\n",
       "      <td>0.230285</td>\n",
       "      <td>0.048037</td>\n",
       "      <td>0.347729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Russian into English  German into English  \\\n",
       "BLEU Star Kendall                      0.216759             0.203917   \n",
       "BLEU Sentence Kendall                  0.179918             0.169787   \n",
       "BLEU Corpus Kendall                    0.056322             0.053605   \n",
       "ROUGE 1 Precision Kendall              0.221403             0.218162   \n",
       "ROUGE 1 Recall Kendall                 0.192943             0.212362   \n",
       "ROUGE 1 Fmeasure Kendall               0.223334             0.227899   \n",
       "ROUGE 2 Precision Kendall              0.219654             0.211056   \n",
       "ROUGE 2 Recall Kendall                 0.205574             0.203474   \n",
       "ROUGE 2 Fmeasure Kendall               0.215878             0.210021   \n",
       "ROUGE L Precision Kendall              0.231716             0.226267   \n",
       "ROUGE L Recall Kendall                 0.209684             0.220059   \n",
       "ROUGE L Fmeasure Kendall               0.232707             0.232192   \n",
       "\n",
       "                           Czech into English  Chinese into English  \\\n",
       "BLEU Star Kendall                    0.287051              0.226367   \n",
       "BLEU Sentence Kendall                0.222721              0.178306   \n",
       "BLEU Corpus Kendall                  0.101863              0.054996   \n",
       "ROUGE 1 Precision Kendall            0.304000              0.240620   \n",
       "ROUGE 1 Recall Kendall               0.249312              0.181416   \n",
       "ROUGE 1 Fmeasure Kendall             0.295210              0.229154   \n",
       "ROUGE 2 Precision Kendall            0.280131              0.214792   \n",
       "ROUGE 2 Recall Kendall               0.253486              0.191793   \n",
       "ROUGE 2 Fmeasure Kendall             0.270441              0.206967   \n",
       "ROUGE L Precision Kendall            0.316472              0.239964   \n",
       "ROUGE L Recall Kendall               0.269153              0.196207   \n",
       "ROUGE L Fmeasure Kendall             0.305452              0.230285   \n",
       "\n",
       "                           English into Chinese  English into Finish  \n",
       "BLEU Star Kendall                      0.011641             0.338281  \n",
       "BLEU Sentence Kendall                  0.011583             0.289645  \n",
       "BLEU Corpus Kendall                    0.290729             0.172336  \n",
       "ROUGE 1 Precision Kendall              0.044400             0.363198  \n",
       "ROUGE 1 Recall Kendall                 0.043840             0.332239  \n",
       "ROUGE 1 Fmeasure Kendall               0.047778             0.354801  \n",
       "ROUGE 2 Precision Kendall              0.058583             0.320441  \n",
       "ROUGE 2 Recall Kendall                 0.059493             0.304527  \n",
       "ROUGE 2 Fmeasure Kendall               0.060129             0.314192  \n",
       "ROUGE L Precision Kendall              0.044429             0.355700  \n",
       "ROUGE L Recall Kendall                 0.044658             0.326671  \n",
       "ROUGE L Fmeasure Kendall               0.048037             0.347729  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendall_df = pd.DataFrame(list(dict_kendall.values()), index=list(dict_kendall.keys()), columns=descriptions)\n",
    "kendall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "reverse-herald",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric with highest correlation</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Russian into English</th>\n",
       "      <td>ROUGE L Fmeasure Kendall</td>\n",
       "      <td>0.232707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German into English</th>\n",
       "      <td>ROUGE L Fmeasure Kendall</td>\n",
       "      <td>0.232192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Czech into English</th>\n",
       "      <td>ROUGE L Precision Kendall</td>\n",
       "      <td>0.316472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinese into English</th>\n",
       "      <td>ROUGE 1 Precision Kendall</td>\n",
       "      <td>0.240620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Chinese</th>\n",
       "      <td>BLEU Corpus Kendall</td>\n",
       "      <td>0.290729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Finish</th>\n",
       "      <td>ROUGE 1 Precision Kendall</td>\n",
       "      <td>0.363198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Metric with highest correlation     Value\n",
       "Russian into English        ROUGE L Fmeasure Kendall  0.232707\n",
       "German into English         ROUGE L Fmeasure Kendall  0.232192\n",
       "Czech into English         ROUGE L Precision Kendall  0.316472\n",
       "Chinese into English       ROUGE 1 Precision Kendall  0.240620\n",
       "English into Chinese             BLEU Corpus Kendall  0.290729\n",
       "English into Finish        ROUGE 1 Precision Kendall  0.363198"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendall_evaluation = pd.DataFrame(kendall_df.idxmax(), columns=[\"Metric with highest correlation\"])\n",
    "kendall_evaluation[\"Value\"] = kendall_df.max()\n",
    "kendall_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-institute",
   "metadata": {},
   "source": [
    "## COMBINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-punch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-passion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-choir",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-campaign",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-investor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-sociology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-aging",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-hampton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-rochester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-mathematics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-trunk",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-first",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-nashville",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
