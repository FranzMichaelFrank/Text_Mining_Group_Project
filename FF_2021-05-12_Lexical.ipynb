{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aboriginal-contamination",
   "metadata": {},
   "source": [
    "# TM Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-thomas",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "final-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coated-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "\n",
    "path_corpus = \"/Users/franz/Desktop/TM Project/corpus/\"\n",
    "\n",
    "ru_en = pd.read_csv(path_corpus + \"ru-en/scores.csv\")\n",
    "de_en = pd.read_csv(path_corpus + \"de-en/scores.csv\")\n",
    "cs_en = pd.read_csv(path_corpus + \"cs-en/scores.csv\")\n",
    "zh_en = pd.read_csv(path_corpus + \"zh-en/scores.csv\")\n",
    "en_zh = pd.read_csv(path_corpus + \"en-zh/scores.csv\")\n",
    "en_fi = pd.read_csv(path_corpus + \"en-fi/scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opponent-updating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr Zeitlupentempo maßen sie, als sie vor Spit...</td>\n",
       "      <td>Her timeless pace measures them when they equi...</td>\n",
       "      <td>Their slow speed was measured by researchers o...</td>\n",
       "      <td>-0.345024</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Er sagte, dass die Bereiche ruhige Treffpunkte...</td>\n",
       "      <td>He said the areas offer quiet meeting points b...</td>\n",
       "      <td>He said the spaces provided calm meeting point...</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>97.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Für die Geschäftsleute an der B 27 ist es nur ...</td>\n",
       "      <td>For businessmen at the B 27, it's only a small...</td>\n",
       "      <td>This is only a small consolation for businesse...</td>\n",
       "      <td>0.700503</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diese Fähigkeit sei möglicherweise angeboren o...</td>\n",
       "      <td>This ability may be born or developed with gen...</td>\n",
       "      <td>This ability may be innate, or may develop as ...</td>\n",
       "      <td>-1.256572</td>\n",
       "      <td>51.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weil sie Wassertemperaturen um die sechs Grad ...</td>\n",
       "      <td>Because they prefer water temperatures around ...</td>\n",
       "      <td>They generally only come to the surface in win...</td>\n",
       "      <td>0.293909</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Ihr Zeitlupentempo maßen sie, als sie vor Spit...   \n",
       "1  Er sagte, dass die Bereiche ruhige Treffpunkte...   \n",
       "2  Für die Geschäftsleute an der B 27 ist es nur ...   \n",
       "3  Diese Fähigkeit sei möglicherweise angeboren o...   \n",
       "4  Weil sie Wassertemperaturen um die sechs Grad ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Her timeless pace measures them when they equi...   \n",
       "1  He said the areas offer quiet meeting points b...   \n",
       "2  For businessmen at the B 27, it's only a small...   \n",
       "3  This ability may be born or developed with gen...   \n",
       "4  Because they prefer water temperatures around ...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Their slow speed was measured by researchers o... -0.345024       76.0   \n",
       "1  He said the spaces provided calm meeting point...  0.903800       97.5   \n",
       "2  This is only a small consolation for businesse...  0.700503       94.0   \n",
       "3  This ability may be innate, or may develop as ... -1.256572       51.5   \n",
       "4  They generally only come to the surface in win...  0.293909       87.0   \n",
       "\n",
       "   annotators  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           2  \n",
       "4           2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-fitness",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "christian-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = [\"Russian into English\", \"German into English\", \"Czech into English\", \"Chinese into English\", \"English into Chinese\", \"English into Finish\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smoking-stroke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>avg z-score</th>\n",
       "      <th>avg avg-score</th>\n",
       "      <th>avg annotators</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Russian into English</th>\n",
       "      <td>17980.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>74.50</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German into English</th>\n",
       "      <td>21704.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.85</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Czech into English</th>\n",
       "      <td>11585.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>69.24</td>\n",
       "      <td>1.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinese into English</th>\n",
       "      <td>26419.0</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>66.06</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Chinese</th>\n",
       "      <td>10221.0</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>65.98</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Finish</th>\n",
       "      <td>6748.0</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>45.12</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         rows  avg z-score  avg avg-score  avg annotators\n",
       "description                                                              \n",
       "Russian into English  17980.0         0.01          74.50            1.30\n",
       "German into English   21704.0         0.00          71.85            1.50\n",
       "Czech into English    11585.0        -0.03          69.24            1.89\n",
       "Chinese into English  26419.0        -0.05          66.06            1.42\n",
       "English into Chinese  10221.0        -0.06          65.98            1.58\n",
       "English into Finish    6748.0        -0.14          45.12            1.23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "zscores = []\n",
    "avgscores = []\n",
    "annots = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    rows.append(element.shape[0])\n",
    "    zscores.append(np.round(element[\"z-score\"].mean(),2))\n",
    "    avgscores.append(np.round(element[\"avg-score\"].mean(), 2))\n",
    "    annots.append(np.round(element[\"annotators\"].mean(),2))\n",
    "    i += 1                   \n",
    "    \n",
    "exploration_df = pd.DataFrame([rows, zscores, avgscores, annots]).T.rename(columns={0:\"rows\", 1:\"avg z-score\", 2:\"avg avg-score\", 3:\"avg annotators\"})\n",
    "exploration_df[\"description\"] = descriptions\n",
    "exploration_df = exploration_df.set_index(\"description\")\n",
    "exploration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "agricultural-selection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>avg z-score</th>\n",
       "      <th>avg avg-score</th>\n",
       "      <th>avg annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rows</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.597505</td>\n",
       "      <td>0.579839</td>\n",
       "      <td>-0.105454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg z-score</th>\n",
       "      <td>0.597505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975645</td>\n",
       "      <td>0.310459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg avg-score</th>\n",
       "      <td>0.579839</td>\n",
       "      <td>0.975645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.417110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg annotators</th>\n",
       "      <td>-0.105454</td>\n",
       "      <td>0.310459</td>\n",
       "      <td>0.417110</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    rows  avg z-score  avg avg-score  avg annotators\n",
       "rows            1.000000     0.597505       0.579839       -0.105454\n",
       "avg z-score     0.597505     1.000000       0.975645        0.310459\n",
       "avg avg-score   0.579839     0.975645       1.000000        0.417110\n",
       "avg annotators -0.105454     0.310459       0.417110        1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploration_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-president",
   "metadata": {},
   "source": [
    "As there are only 6 different types of translations, these correlations might be not very meaningful!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-intellectual",
   "metadata": {},
   "source": [
    "# Lexical metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-explanation",
   "metadata": {},
   "source": [
    "## BLEU Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-greenhouse",
   "metadata": {},
   "source": [
    "The BLEU Score might require multiple reference sentences!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-desperate",
   "metadata": {},
   "source": [
    "### 1st Try"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-trademark",
   "metadata": {},
   "source": [
    "Inspiration taken from \n",
    "* https://www.journaldev.com/46659/bleu-score-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "million-yeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCorrelation between z-score and BLEU score\n",
      "\n",
      "\u001b[1m Russian into English: \u001b[0mPearson: 0.248 | Kendall: 0.1799\n",
      "\u001b[1m German into English: \u001b[0mPearson: 0.2415 | Kendall: 0.1698\n",
      "\u001b[1m Czech into English: \u001b[0mPearson: 0.2831 | Kendall: 0.2227\n",
      "\u001b[1m Chinese into English: \u001b[0mPearson: 0.2482 | Kendall: 0.1783\n",
      "\u001b[1m English into Chinese: \u001b[0mPearson: 0.0183 | Kendall: 0.0116\n",
      "\u001b[1m English into Finish: \u001b[0mPearson: 0.2623 | Kendall: 0.2896\n",
      "\n",
      "\u001b[1mOverall:\u001b[0m Average Pearson: 0.2169 | Average Kendall: 0.1753\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    bleu_scores = []\n",
    "\n",
    "    #calculating the bleu scores for the translations in comparison to their respective reference\n",
    "    for i in range(6748): #element.shape[0]\n",
    "        reference = [element.loc[i,\"reference\"].split()]\n",
    "        translation = element.loc[i,\"translation\"].split()\n",
    "        bleu_scores.append(sentence_bleu(reference, translation,weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n",
    "    #add the bleu scores to the dataframe\n",
    "    development_df = element.iloc[:6748,:].copy() #element.shape[0]\n",
    "    development_df[\"BLEU\"] = bleu_scores\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "\n",
    "\n",
    "print(\"\\033[1mCorrelation between z-score and BLEU score\\n\")\n",
    "i = 0\n",
    "for element in correlations_p:\n",
    "    print(\"\\033[1m\", descriptions[i] + \":\",  \"\\033[0mPearson:\", np.round(element,4), \"| Kendall:\", np.round(correlations_k[i],4))\n",
    "    i += 1\n",
    "\n",
    "print(\"\\n\\033[1mOverall:\\033[0m Average Pearson:\", np.round(sum(correlations_p)/len(correlations_p),4),\n",
    "         \"| Average Kendall:\", np.round(sum(correlations_k)/len(correlations_k),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-amber",
   "metadata": {},
   "source": [
    "### 2nd Try"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-budget",
   "metadata": {},
   "source": [
    "Inspiration taken from:\n",
    "* https://stackoverflow.com/questions/62337356/bleu-error-n-gram-overlaps-of-lower-order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adolescent-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCorrelation between z-score and BLEU score\n",
      "\n",
      "\u001b[1m Russian into English: \u001b[0mPearson 0.0346 | Kendall: 0.0563\n",
      "\u001b[1m German into English: \u001b[0mPearson 0.0355 | Kendall: 0.0536\n",
      "\u001b[1m Czech into English: \u001b[0mPearson 0.1055 | Kendall: 0.1019\n",
      "\u001b[1m Chinese into English: \u001b[0mPearson 0.0587 | Kendall: 0.055\n",
      "\u001b[1m English into Chinese: \u001b[0mPearson 0.4144 | Kendall: 0.2907\n",
      "\u001b[1m English into Finish: \u001b[0mPearson 0.2355 | Kendall: 0.1723\n",
      "\n",
      "\u001b[1mOverall:\u001b[0m Average Pearson: 0.1474 | Average Kendall: 0.1216\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    bleu_scores = []\n",
    "\n",
    "    #calculating the bleu scores for the translations in comparison to their respective reference\n",
    "    for i in range(6748): #element.shape[0]\n",
    "        reference = [element.loc[i,\"reference\"].split()]\n",
    "        translation = element.loc[i,\"translation\"].split()\n",
    "        while len(reference) < len(translation):\n",
    "            reference.append(\" \")\n",
    "        while len(reference) > len(translation):\n",
    "            translation.append(\" \")\n",
    "        bleu_scores.append(corpus_bleu(reference, translation))\n",
    "\n",
    "    #add the bleu scores to the dataframe\n",
    "    development_df = element.iloc[:6748,:].copy() #element.shape[0]\n",
    "    development_df[\"BLEU\"] = bleu_scores\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "\n",
    "\n",
    "print(\"\\033[1mCorrelation between z-score and BLEU score\\n\")\n",
    "i = 0\n",
    "for element in correlations_p:\n",
    "    print(\"\\033[1m\", descriptions[i] + \":\",  \"\\033[0mPearson\", np.round(element,4), \"| Kendall:\", np.round(correlations_k[i],4))\n",
    "    i += 1\n",
    "\n",
    "print(\"\\n\\033[1mOverall:\\033[0m Average Pearson:\", np.round(sum(correlations_p)/len(correlations_p),4),\n",
    "         \"| Average Kendall:\", np.round(sum(correlations_k)/len(correlations_k),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-divide",
   "metadata": {},
   "source": [
    "## ROUGE Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-cooperation",
   "metadata": {},
   "source": [
    "Inspiration taken from:\n",
    "* https://pypi.org/project/rouge-score/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stock-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --target=/Users/franz/opt/anaconda3/envs/Data_visualization/lib/python3.8/site-packages/ rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-donor",
   "metadata": {},
   "source": [
    "### ROUGE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "everyday-oxford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPearson Correlation between z-score and ROUGE measures (rouge1) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.333682</td>\n",
       "      <td>0.308229</td>\n",
       "      <td>0.450566</td>\n",
       "      <td>0.360388</td>\n",
       "      <td>0.066999</td>\n",
       "      <td>0.549302</td>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.287828</td>\n",
       "      <td>0.299770</td>\n",
       "      <td>0.376656</td>\n",
       "      <td>0.279403</td>\n",
       "      <td>0.065452</td>\n",
       "      <td>0.513220</td>\n",
       "      <td>0.303721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.332984</td>\n",
       "      <td>0.326371</td>\n",
       "      <td>0.440464</td>\n",
       "      <td>0.348995</td>\n",
       "      <td>0.071994</td>\n",
       "      <td>0.544540</td>\n",
       "      <td>0.344225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.333682             0.308229   \n",
       "ROUGE recall                 0.287828             0.299770   \n",
       "ROUGE fmeasure               0.332984             0.326371   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.450566              0.360388   \n",
       "ROUGE recall               0.376656              0.279403   \n",
       "ROUGE fmeasure             0.440464              0.348995   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.066999             0.549302  0.344861  \n",
       "ROUGE recall                 0.065452             0.513220  0.303721  \n",
       "ROUGE fmeasure               0.071994             0.544540  0.344225  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "results_p = pd.DataFrame()\n",
    "results_k = pd.DataFrame()\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "j = 0\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    fmeasures = []\n",
    "\n",
    "    #calculating the rouge scores for the translations in comparison to their respective reference\n",
    "    for i in range(6748): #element.shape[0]\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(element.loc[i,\"reference\"], element.loc[i,\"translation\"])\n",
    "        precisions.append(scores[\"rouge1\"].precision)\n",
    "        recalls.append(scores[\"rouge1\"].recall)\n",
    "        fmeasures.append(scores[\"rouge1\"].fmeasure)\n",
    "\n",
    "    #add the rouge scores to the dataframe\n",
    "    development_df = element.iloc[:6748,:].copy() #element.shape[0]\n",
    "    development_df[\"ROUGE precision\"] = precisions\n",
    "    development_df[\"ROUGE recall\"] = recalls\n",
    "    development_df[\"ROUGE fmeasure\"] = fmeasures\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "    col_name = descriptions[j]\n",
    "    j += 1\n",
    "    results_p[col_name] = pd.Series(development_df.corr(method=\"pearson\").iloc[0,3:])\n",
    "    results_k[col_name] = pd.Series(development_df.corr(method=\"kendall\").iloc[0,3:])\n",
    "\n",
    "\n",
    "print(\"\\033[1mPearson Correlation between z-score and ROUGE measures (rouge1) \\n\")\n",
    "\n",
    "results_p[\"Average\"] = results_p.T.mean()\n",
    "results_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "shared-death",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mKendall Tau Correlation between z-score and ROUGE measures (rouge1) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.221403</td>\n",
       "      <td>0.218162</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.240620</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.363198</td>\n",
       "      <td>0.231964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.192943</td>\n",
       "      <td>0.212362</td>\n",
       "      <td>0.249312</td>\n",
       "      <td>0.181416</td>\n",
       "      <td>0.043840</td>\n",
       "      <td>0.332239</td>\n",
       "      <td>0.202019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.223334</td>\n",
       "      <td>0.227899</td>\n",
       "      <td>0.295210</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>0.047778</td>\n",
       "      <td>0.354801</td>\n",
       "      <td>0.229696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.221403             0.218162   \n",
       "ROUGE recall                 0.192943             0.212362   \n",
       "ROUGE fmeasure               0.223334             0.227899   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.304000              0.240620   \n",
       "ROUGE recall               0.249312              0.181416   \n",
       "ROUGE fmeasure             0.295210              0.229154   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.044400             0.363198  0.231964  \n",
       "ROUGE recall                 0.043840             0.332239  0.202019  \n",
       "ROUGE fmeasure               0.047778             0.354801  0.229696  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\033[1mKendall Tau Correlation between z-score and ROUGE measures (rouge1) \\n\")\n",
    "\n",
    "results_k[\"Average\"] = results_k.T.mean()\n",
    "results_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-valley",
   "metadata": {},
   "source": [
    "### ROUGE L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "thermal-virgin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPearson Correlation between z-score and ROUGE measures (rougeL) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.341043</td>\n",
       "      <td>0.317401</td>\n",
       "      <td>0.467481</td>\n",
       "      <td>0.354257</td>\n",
       "      <td>0.068515</td>\n",
       "      <td>0.540008</td>\n",
       "      <td>0.348118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.304441</td>\n",
       "      <td>0.309437</td>\n",
       "      <td>0.402230</td>\n",
       "      <td>0.291957</td>\n",
       "      <td>0.068080</td>\n",
       "      <td>0.505371</td>\n",
       "      <td>0.313586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.340184</td>\n",
       "      <td>0.331321</td>\n",
       "      <td>0.455608</td>\n",
       "      <td>0.346621</td>\n",
       "      <td>0.074154</td>\n",
       "      <td>0.535137</td>\n",
       "      <td>0.347171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.341043             0.317401   \n",
       "ROUGE recall                 0.304441             0.309437   \n",
       "ROUGE fmeasure               0.340184             0.331321   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.467481              0.354257   \n",
       "ROUGE recall               0.402230              0.291957   \n",
       "ROUGE fmeasure             0.455608              0.346621   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.068515             0.540008  0.348118  \n",
       "ROUGE recall                 0.068080             0.505371  0.313586  \n",
       "ROUGE fmeasure               0.074154             0.535137  0.347171  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "results_p = pd.DataFrame()\n",
    "results_k = pd.DataFrame()\n",
    "\n",
    "correlations_p = []\n",
    "correlations_k = []\n",
    "j = 0\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    fmeasures = []\n",
    "\n",
    "    #calculating the rouge scores for the translations in comparison to their respective reference\n",
    "    for i in range(6748): #element.shape[0]\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(element.loc[i,\"reference\"], element.loc[i,\"translation\"])\n",
    "        precisions.append(scores[\"rougeL\"].precision)\n",
    "        recalls.append(scores[\"rougeL\"].recall)\n",
    "        fmeasures.append(scores[\"rougeL\"].fmeasure)\n",
    "\n",
    "    #add the rouge scores to the dataframe\n",
    "    development_df = element.iloc[:6748,:].copy() #element.shape[0]\n",
    "    development_df[\"ROUGE precision\"] = precisions\n",
    "    development_df[\"ROUGE recall\"] = recalls\n",
    "    development_df[\"ROUGE fmeasure\"] = fmeasures\n",
    "    correlations_p.append(development_df.corr(method=\"pearson\").iloc[-1:,0].values[0])\n",
    "    correlations_k.append(development_df.corr(method=\"kendall\").iloc[-1:,0].values[0])\n",
    "    col_name = descriptions[j]\n",
    "    j += 1\n",
    "    results_p[col_name] = pd.Series(development_df.corr(method=\"pearson\").iloc[0,3:])\n",
    "    results_k[col_name] = pd.Series(development_df.corr(method=\"kendall\").iloc[0,3:])\n",
    "\n",
    "\n",
    "print(\"\\033[1mPearson Correlation between z-score and ROUGE measures (rougeL) \\n\")\n",
    "\n",
    "results_p[\"Average\"] = results_p.T.mean()\n",
    "results_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "increased-millennium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mKendall Tau Correlation between z-score and ROUGE measures (rougeL) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Russian into English</th>\n",
       "      <th>German into English</th>\n",
       "      <th>Czech into English</th>\n",
       "      <th>Chinese into English</th>\n",
       "      <th>English into Chinese</th>\n",
       "      <th>English into Finish</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROUGE precision</th>\n",
       "      <td>0.231716</td>\n",
       "      <td>0.226267</td>\n",
       "      <td>0.316472</td>\n",
       "      <td>0.239964</td>\n",
       "      <td>0.044429</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.235758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE recall</th>\n",
       "      <td>0.209684</td>\n",
       "      <td>0.220059</td>\n",
       "      <td>0.269153</td>\n",
       "      <td>0.196207</td>\n",
       "      <td>0.044658</td>\n",
       "      <td>0.326671</td>\n",
       "      <td>0.211072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "      <td>0.232707</td>\n",
       "      <td>0.232192</td>\n",
       "      <td>0.305452</td>\n",
       "      <td>0.230285</td>\n",
       "      <td>0.048037</td>\n",
       "      <td>0.347729</td>\n",
       "      <td>0.232734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Russian into English  German into English  \\\n",
       "ROUGE precision              0.231716             0.226267   \n",
       "ROUGE recall                 0.209684             0.220059   \n",
       "ROUGE fmeasure               0.232707             0.232192   \n",
       "\n",
       "                 Czech into English  Chinese into English  \\\n",
       "ROUGE precision            0.316472              0.239964   \n",
       "ROUGE recall               0.269153              0.196207   \n",
       "ROUGE fmeasure             0.305452              0.230285   \n",
       "\n",
       "                 English into Chinese  English into Finish   Average  \n",
       "ROUGE precision              0.044429             0.355700  0.235758  \n",
       "ROUGE recall                 0.044658             0.326671  0.211072  \n",
       "ROUGE fmeasure               0.048037             0.347729  0.232734  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\033[1mKendall Tau Correlation between z-score and ROUGE measures (rougeL) \\n\")\n",
    "\n",
    "results_k[\"Average\"] = results_k.T.mean()\n",
    "results_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-punch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-solution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-jamaica",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-punch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-omega",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-passion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-choir",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-campaign",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-investor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-sociology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-aging",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-hampton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-rochester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-mathematics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-trunk",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-first",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-nashville",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
