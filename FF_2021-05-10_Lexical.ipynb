{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aboriginal-contamination",
   "metadata": {},
   "source": [
    "# TM Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-thomas",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "final-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coated-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "\n",
    "path_corpus = \"/Users/franz/Desktop/TM Project/corpus/\"\n",
    "\n",
    "ru_en = pd.read_csv(path_corpus + \"ru-en/scores.csv\")\n",
    "de_en = pd.read_csv(path_corpus + \"de-en/scores.csv\")\n",
    "cs_en = pd.read_csv(path_corpus + \"cs-en/scores.csv\")\n",
    "zh_en = pd.read_csv(path_corpus + \"zh-en/scores.csv\")\n",
    "en_zh = pd.read_csv(path_corpus + \"en-zh/scores.csv\")\n",
    "en_fi = pd.read_csv(path_corpus + \"en-fi/scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opponent-updating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr Zeitlupentempo maßen sie, als sie vor Spit...</td>\n",
       "      <td>Her timeless pace measures them when they equi...</td>\n",
       "      <td>Their slow speed was measured by researchers o...</td>\n",
       "      <td>-0.345024</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Er sagte, dass die Bereiche ruhige Treffpunkte...</td>\n",
       "      <td>He said the areas offer quiet meeting points b...</td>\n",
       "      <td>He said the spaces provided calm meeting point...</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>97.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Für die Geschäftsleute an der B 27 ist es nur ...</td>\n",
       "      <td>For businessmen at the B 27, it's only a small...</td>\n",
       "      <td>This is only a small consolation for businesse...</td>\n",
       "      <td>0.700503</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diese Fähigkeit sei möglicherweise angeboren o...</td>\n",
       "      <td>This ability may be born or developed with gen...</td>\n",
       "      <td>This ability may be innate, or may develop as ...</td>\n",
       "      <td>-1.256572</td>\n",
       "      <td>51.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weil sie Wassertemperaturen um die sechs Grad ...</td>\n",
       "      <td>Because they prefer water temperatures around ...</td>\n",
       "      <td>They generally only come to the surface in win...</td>\n",
       "      <td>0.293909</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Ihr Zeitlupentempo maßen sie, als sie vor Spit...   \n",
       "1  Er sagte, dass die Bereiche ruhige Treffpunkte...   \n",
       "2  Für die Geschäftsleute an der B 27 ist es nur ...   \n",
       "3  Diese Fähigkeit sei möglicherweise angeboren o...   \n",
       "4  Weil sie Wassertemperaturen um die sechs Grad ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Her timeless pace measures them when they equi...   \n",
       "1  He said the areas offer quiet meeting points b...   \n",
       "2  For businessmen at the B 27, it's only a small...   \n",
       "3  This ability may be born or developed with gen...   \n",
       "4  Because they prefer water temperatures around ...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Their slow speed was measured by researchers o... -0.345024       76.0   \n",
       "1  He said the spaces provided calm meeting point...  0.903800       97.5   \n",
       "2  This is only a small consolation for businesse...  0.700503       94.0   \n",
       "3  This ability may be innate, or may develop as ... -1.256572       51.5   \n",
       "4  They generally only come to the surface in win...  0.293909       87.0   \n",
       "\n",
       "   annotators  \n",
       "0           1  \n",
       "1           2  \n",
       "2           1  \n",
       "3           2  \n",
       "4           2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-fitness",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "christian-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = [\"Russian into English\", \"German into English\", \"Czech into English\", \"Chinese into English\", \"English into Chinese\", \"English into Finish\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smoking-stroke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>avg z-score</th>\n",
       "      <th>avg avg-score</th>\n",
       "      <th>avg annotators</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Russian into English</th>\n",
       "      <td>17980.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>74.50</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>German into English</th>\n",
       "      <td>21704.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.85</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Czech into English</th>\n",
       "      <td>11585.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>69.24</td>\n",
       "      <td>1.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinese into English</th>\n",
       "      <td>26419.0</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>66.06</td>\n",
       "      <td>1.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Chinese</th>\n",
       "      <td>10221.0</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>65.98</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>English into Finish</th>\n",
       "      <td>6748.0</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>45.12</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         rows  avg z-score  avg avg-score  avg annotators\n",
       "description                                                              \n",
       "Russian into English  17980.0         0.01          74.50            1.30\n",
       "German into English   21704.0         0.00          71.85            1.50\n",
       "Czech into English    11585.0        -0.03          69.24            1.89\n",
       "Chinese into English  26419.0        -0.05          66.06            1.42\n",
       "English into Chinese  10221.0        -0.06          65.98            1.58\n",
       "English into Finish    6748.0        -0.14          45.12            1.23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "zscores = []\n",
    "avgscores = []\n",
    "annots = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    rows.append(element.shape[0])\n",
    "    zscores.append(np.round(element[\"z-score\"].mean(),2))\n",
    "    avgscores.append(np.round(element[\"avg-score\"].mean(), 2))\n",
    "    annots.append(np.round(element[\"annotators\"].mean(),2))\n",
    "    i += 1                   \n",
    "    \n",
    "exploration_df = pd.DataFrame([rows, zscores, avgscores, annots]).T.rename(columns={0:\"rows\", 1:\"avg z-score\", 2:\"avg avg-score\", 3:\"avg annotators\"})\n",
    "exploration_df[\"description\"] = descriptions\n",
    "exploration_df = exploration_df.set_index(\"description\")\n",
    "exploration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "agricultural-selection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>avg z-score</th>\n",
       "      <th>avg avg-score</th>\n",
       "      <th>avg annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rows</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.597505</td>\n",
       "      <td>0.579839</td>\n",
       "      <td>-0.105454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg z-score</th>\n",
       "      <td>0.597505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975645</td>\n",
       "      <td>0.310459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg avg-score</th>\n",
       "      <td>0.579839</td>\n",
       "      <td>0.975645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.417110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg annotators</th>\n",
       "      <td>-0.105454</td>\n",
       "      <td>0.310459</td>\n",
       "      <td>0.417110</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    rows  avg z-score  avg avg-score  avg annotators\n",
       "rows            1.000000     0.597505       0.579839       -0.105454\n",
       "avg z-score     0.597505     1.000000       0.975645        0.310459\n",
       "avg avg-score   0.579839     0.975645       1.000000        0.417110\n",
       "avg annotators -0.105454     0.310459       0.417110        1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploration_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-president",
   "metadata": {},
   "source": [
    "As there are only 6 different types of translations, these correlations might be not very meaningful!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-intellectual",
   "metadata": {},
   "source": [
    "# Lexical metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-explanation",
   "metadata": {},
   "source": [
    "## BLEU Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-greenhouse",
   "metadata": {},
   "source": [
    "The BLEU Score might require multiple reference sentences!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-desperate",
   "metadata": {},
   "source": [
    "### 1st Try"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-trademark",
   "metadata": {},
   "source": [
    "Inspiration taken from \n",
    "* https://www.journaldev.com/46659/bleu-score-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "million-yeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/franz/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCorrelation between z-score and BLEU score\n",
      "\n",
      "\u001b[1m Russian into English: \u001b[0m 0.2016\n",
      "\u001b[1m German into English: \u001b[0m 0.2337\n",
      "\u001b[1m Czech into English: \u001b[0m 0.2638\n",
      "\u001b[1m Chinese into English: \u001b[0m 0.2362\n",
      "\u001b[1m English into Chinese: \u001b[0m nan\n",
      "\u001b[1m English into Finish: \u001b[0m 0.2153\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "correlations = []\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    bleu_scores = []\n",
    "\n",
    "    #calculating the bleu scores for the translations in comparison to their respective reference\n",
    "    for i in range(2000): #element.shape[0]\n",
    "        reference = [element.loc[i,\"reference\"].split()]\n",
    "        translation = element.loc[i,\"translation\"].split()\n",
    "        bleu_scores.append(sentence_bleu(reference, translation,weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n",
    "    #add the bleu scores to the dataframe\n",
    "    development_df = element.iloc[:2000,:].copy() #element.shape[0]\n",
    "    development_df[\"BLEU\"] = bleu_scores\n",
    "    correlations.append(development_df.corr().iloc[-1:,0].values[0])\n",
    "\n",
    "\n",
    "print(\"\\033[1mCorrelation between z-score and BLEU score\\n\")\n",
    "i = 0\n",
    "for element in correlations:\n",
    "    print(\"\\033[1m\", descriptions[i] + \":\",  \"\\033[0m\", np.round(element,4))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-amber",
   "metadata": {},
   "source": [
    "### 2nd Try"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-budget",
   "metadata": {},
   "source": [
    "Inspiration taken from:\n",
    "* https://stackoverflow.com/questions/62337356/bleu-error-n-gram-overlaps-of-lower-order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adolescent-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCorrelation between z-score and BLEU score\n",
      "\n",
      "\u001b[1m Russian into English: \u001b[0m 0.0365\n",
      "\u001b[1m German into English: \u001b[0m 0.0776\n",
      "\u001b[1m Czech into English: \u001b[0m 0.0996\n",
      "\u001b[1m Chinese into English: \u001b[0m 0.0445\n",
      "\u001b[1m English into Chinese: \u001b[0m 0.3935\n",
      "\u001b[1m English into Finish: \u001b[0m 0.122\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "correlations = []\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    bleu_scores = []\n",
    "\n",
    "    #calculating the bleu scores for the translations in comparison to their respective reference\n",
    "    for i in range(2000): #element.shape[0]\n",
    "        reference = [element.loc[i,\"reference\"].split()]\n",
    "        translation = element.loc[i,\"translation\"].split()\n",
    "        while len(reference) < len(translation):\n",
    "            reference.append(\" \")\n",
    "        while len(reference) > len(translation):\n",
    "            translation.append(\" \")\n",
    "        bleu_scores.append(corpus_bleu(reference, translation))\n",
    "\n",
    "    #add the bleu scores to the dataframe\n",
    "    development_df = element.iloc[:2000,:].copy() #element.shape[0]\n",
    "    development_df[\"BLEU\"] = bleu_scores\n",
    "    correlations.append(development_df.corr().iloc[-1:,0].values[0])\n",
    "\n",
    "\n",
    "print(\"\\033[1mCorrelation between z-score and BLEU score\\n\")\n",
    "i = 0\n",
    "for element in correlations:\n",
    "    print(\"\\033[1m\", descriptions[i] + \":\",  \"\\033[0m\", np.round(element,4))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-divide",
   "metadata": {},
   "source": [
    "## ROUGE Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-cooperation",
   "metadata": {},
   "source": [
    "Inspiration taken from:\n",
    "* https://pypi.org/project/rouge-score/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stock-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --target=/Users/franz/opt/anaconda3/envs/Data_visualization/lib/python3.8/site-packages/ rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "controversial-nightlife",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCorrelation between z-score and ROUGE measures\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROUGE precision</th>\n",
       "      <th>ROUGE recall</th>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>0.549302</td>\n",
       "      <td>0.51322</td>\n",
       "      <td>0.54454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ROUGE precision  ROUGE recall  ROUGE fmeasure\n",
       "z-score         0.549302       0.51322         0.54454"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "correlations = []\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    fmeasures = []\n",
    "\n",
    "    #calculating the bleu scores for the translations in comparison to their respective reference\n",
    "    for i in range(6748): #element.shape[0]\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(element.loc[i,\"reference\"], element.loc[i,\"translation\"])\n",
    "        precisions.append(scores[\"rouge1\"].precision)\n",
    "        recalls.append(scores[\"rouge1\"].recall)\n",
    "        fmeasures.append(scores[\"rouge1\"].fmeasure)\n",
    "\n",
    "    #add the bleu scores to the dataframe\n",
    "    development_df = element.iloc[:6748,:].copy() #element.shape[0]\n",
    "    development_df[\"ROUGE precision\"] = precisions\n",
    "    development_df[\"ROUGE recall\"] = recalls\n",
    "    development_df[\"ROUGE fmeasure\"] = fmeasures\n",
    "    correlations.append(development_df.corr().iloc[-1:,0].values[0])\n",
    "\n",
    "\n",
    "print(\"\\033[1mCorrelation between z-score and ROUGE measures\\n\")\n",
    "\n",
    "pd.DataFrame(development_df.corr().iloc[0,3:]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "technical-sunset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mCorrelation between z-score and ROUGE measures\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROUGE precision</th>\n",
       "      <th>ROUGE recall</th>\n",
       "      <th>ROUGE fmeasure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>z-score</th>\n",
       "      <td>0.540008</td>\n",
       "      <td>0.505371</td>\n",
       "      <td>0.535137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ROUGE precision  ROUGE recall  ROUGE fmeasure\n",
       "z-score         0.540008      0.505371        0.535137"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "correlations = []\n",
    "\n",
    "for element in [ru_en, de_en, cs_en, zh_en, en_zh, en_fi]:\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    fmeasures = []\n",
    "\n",
    "    #calculating the bleu scores for the translations in comparison to their respective reference\n",
    "    for i in range(6748): #element.shape[0]\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(element.loc[i,\"reference\"], element.loc[i,\"translation\"])\n",
    "        precisions.append(scores[\"rougeL\"].precision)\n",
    "        recalls.append(scores[\"rougeL\"].recall)\n",
    "        fmeasures.append(scores[\"rougeL\"].fmeasure)\n",
    "\n",
    "    #add the bleu scores to the dataframe\n",
    "    development_df = element.iloc[:6748,:].copy() #element.shape[0]\n",
    "    development_df[\"ROUGE precision\"] = precisions\n",
    "    development_df[\"ROUGE recall\"] = recalls\n",
    "    development_df[\"ROUGE fmeasure\"] = fmeasures\n",
    "    correlations.append(development_df.corr().iloc[-1:,0].values[0])\n",
    "\n",
    "\n",
    "print(\"\\033[1mCorrelation between z-score and ROUGE measures\\n\")\n",
    "\n",
    "pd.DataFrame(development_df.corr().iloc[0,3:]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-receptor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-virgin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-millennium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-punch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-solution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-jamaica",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-punch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-omega",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-passion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-choir",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-campaign",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-investor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-sociology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-aging",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-hampton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-rochester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-mathematics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-trunk",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-first",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-nashville",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
